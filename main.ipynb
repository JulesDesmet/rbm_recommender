{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyter==1.0.0 in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.0.0)\r\n",
      "Requirement already satisfied: numpy==1.21.3 in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (1.21.3)\r\n",
      "Requirement already satisfied: matplotlib==3.4.3 in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (3.4.3)\r\n",
      "Requirement already satisfied: pandas==1.3.4 in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (1.3.4)\r\n",
      "Requirement already satisfied: scikit-learn==1.0.1 in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (1.0.1)\r\n",
      "Requirement already satisfied: torch==1.10.0 in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (1.10.0)\r\n",
      "Requirement already satisfied: tqdm==4.62.3 in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (4.62.3)\r\n",
      "Requirement already satisfied: notebook in ./venv/lib/python3.9/site-packages (from jupyter==1.0.0->-r requirements.txt (line 1)) (6.4.4)\r\n",
      "Requirement already satisfied: ipywidgets in ./venv/lib/python3.9/site-packages (from jupyter==1.0.0->-r requirements.txt (line 1)) (7.6.5)\r\n",
      "Requirement already satisfied: nbconvert in ./venv/lib/python3.9/site-packages (from jupyter==1.0.0->-r requirements.txt (line 1)) (6.2.0)\r\n",
      "Requirement already satisfied: jupyter-console in ./venv/lib/python3.9/site-packages (from jupyter==1.0.0->-r requirements.txt (line 1)) (6.4.0)\r\n",
      "Requirement already satisfied: qtconsole in ./venv/lib/python3.9/site-packages (from jupyter==1.0.0->-r requirements.txt (line 1)) (5.1.1)\r\n",
      "Requirement already satisfied: ipykernel in ./venv/lib/python3.9/site-packages (from jupyter==1.0.0->-r requirements.txt (line 1)) (6.4.1)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/jules/.local/lib/python3.9/site-packages (from matplotlib==3.4.3->-r requirements.txt (line 3)) (2.4.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/lib/python3/dist-packages (from matplotlib==3.4.3->-r requirements.txt (line 3)) (2.7.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/jules/.local/lib/python3.9/site-packages (from matplotlib==3.4.3->-r requirements.txt (line 3)) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jules/.local/lib/python3.9/site-packages (from matplotlib==3.4.3->-r requirements.txt (line 3)) (0.10.0)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/jules/.local/lib/python3.9/site-packages (from matplotlib==3.4.3->-r requirements.txt (line 3)) (8.2.0)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/lib/python3/dist-packages (from pandas==1.3.4->-r requirements.txt (line 4)) (2019.3)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/jules/.local/lib/python3.9/site-packages (from scikit-learn==1.0.1->-r requirements.txt (line 5)) (2.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /home/jules/.local/lib/python3.9/site-packages (from scikit-learn==1.0.1->-r requirements.txt (line 5)) (0.17.0)\r\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/jules/.local/lib/python3.9/site-packages (from scikit-learn==1.0.1->-r requirements.txt (line 5)) (1.6.3)\r\n",
      "Requirement already satisfied: typing-extensions in /home/jules/.local/lib/python3.9/site-packages (from torch==1.10.0->-r requirements.txt (line 6)) (3.10.0.2)\r\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from cycler>=0.10->matplotlib==3.4.3->-r requirements.txt (line 3)) (1.14.0)\r\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (0.1.3)\r\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (1.5.0)\r\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (6.1)\r\n",
      "Requirement already satisfied: ipython-genutils in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (0.2.0)\r\n",
      "Requirement already satisfied: jupyter-client<8.0 in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (7.0.6)\r\n",
      "Requirement already satisfied: traitlets<6.0,>=4.1.0 in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (5.1.0)\r\n",
      "Requirement already satisfied: ipython<8.0,>=7.23.1 in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (7.28.0)\r\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in ./venv/lib/python3.9/site-packages (from ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (1.0.2)\r\n",
      "Requirement already satisfied: nbformat>=4.2.0 in ./venv/lib/python3.9/site-packages (from ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (5.1.3)\r\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in ./venv/lib/python3.9/site-packages (from ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (3.5.1)\r\n",
      "Requirement already satisfied: pygments in ./venv/lib/python3.9/site-packages (from jupyter-console->jupyter==1.0.0->-r requirements.txt (line 1)) (2.10.0)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in ./venv/lib/python3.9/site-packages (from jupyter-console->jupyter==1.0.0->-r requirements.txt (line 1)) (3.0.20)\r\n",
      "Requirement already satisfied: bleach in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (4.1.0)\r\n",
      "Requirement already satisfied: jinja2>=2.4 in /usr/lib/python3/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (2.10.1)\r\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/lib/python3/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.3)\r\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.5.4)\r\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.8.4)\r\n",
      "Requirement already satisfied: testpath in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.5.0)\r\n",
      "Requirement already satisfied: defusedxml in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.7.1)\r\n",
      "Requirement already satisfied: jupyterlab-pygments in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.1.2)\r\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (1.5.0)\r\n",
      "Requirement already satisfied: jupyter-core in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (4.8.1)\r\n",
      "Requirement already satisfied: pyzmq>=17 in ./venv/lib/python3.9/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (22.3.0)\r\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in ./venv/lib/python3.9/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (1.8.0)\r\n",
      "Requirement already satisfied: prometheus-client in ./venv/lib/python3.9/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (0.11.0)\r\n",
      "Requirement already satisfied: terminado>=0.8.3 in ./venv/lib/python3.9/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (0.12.1)\r\n",
      "Requirement already satisfied: argon2-cffi in ./venv/lib/python3.9/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (21.1.0)\r\n",
      "Requirement already satisfied: qtpy in ./venv/lib/python3.9/site-packages (from qtconsole->jupyter==1.0.0->-r requirements.txt (line 1)) (1.11.2)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /home/jules/.local/lib/python3.9/site-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (0.17.2)\r\n",
      "Requirement already satisfied: decorator in ./venv/lib/python3.9/site-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (5.1.0)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/lib/python3/dist-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (4.6.0)\r\n",
      "Requirement already satisfied: pickleshare in ./venv/lib/python3.9/site-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (0.7.5)\r\n",
      "Requirement already satisfied: setuptools>=18.5 in ./venv/lib/python3.9/site-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (58.1.0)\r\n",
      "Requirement already satisfied: backcall in ./venv/lib/python3.9/site-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (0.2.0)\r\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in ./venv/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (1.5.1)\r\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in ./venv/lib/python3.9/site-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (4.1.0)\r\n",
      "Requirement already satisfied: wcwidth in ./venv/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter==1.0.0->-r requirements.txt (line 1)) (0.2.5)\r\n",
      "Requirement already satisfied: ptyprocess in ./venv/lib/python3.9/site-packages (from terminado>=0.8.3->notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (0.7.0)\r\n",
      "Requirement already satisfied: cffi>=1.0.0 in ./venv/lib/python3.9/site-packages (from argon2-cffi->notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (1.14.6)\r\n",
      "Requirement already satisfied: webencodings in ./venv/lib/python3.9/site-packages (from bleach->nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.5.1)\r\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.9/site-packages (from bleach->nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (21.0)\r\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.9/site-packages (from cffi>=1.0.0->argon2-cffi->notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (2.20)\r\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /home/jules/.local/lib/python3.9/site-packages (from jedi>=0.16->ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (0.7.1)\r\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in ./venv/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (0.18.0)\r\n",
      "Requirement already satisfied: attrs>=17.4.0 in ./venv/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (21.2.0)\r\n",
      "\u001B[33mWARNING: You are using pip version 21.3; however, version 21.3.1 is available.\r\n",
      "You should consider upgrading via the '/home/jules/Documents/rbm_recommender/venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "from json import loads\n",
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from IPython.display import display  # removes unnecessary error reports in PyCharm\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(\"Using device\", device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def parse_json(filename: str, read_max: int = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads the file line by line, parsing each line as json.\n",
    "    \"\"\"\n",
    "    file = gzip.open(filename, \"r\")\n",
    "    data = []\n",
    "    for index, line in enumerate(tqdm(file)):\n",
    "        if index == read_max:\n",
    "            break\n",
    "        data.append(loads(line))\n",
    "    print(f\"Read {len(data)} rows.\")\n",
    "    return pd.DataFrame.from_dict(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset\n",
    "\n",
    "The dataset consists of three separate files:\n",
    "\n",
    "- The books; we will only need this data to make sense of the recommendations. Using this data to make recommendations\n",
    "is (at least for now) not required for the project. It would require analysis and comparisons of the books, which is not\n",
    "a part of the base algorithm. However, being able to show which books are being recommended, rather than just showing an\n",
    "ID, is quite valuable in itself.\n",
    "\n",
    "- The reviews; this file contains all the reviews and associated ratings that the users have given. This is essentially\n",
    "the explicit feedback that we can use to generate recommendations.\n",
    "\n",
    "- The interactions; this file contains all the interactions between users and books. It contains explicit and implicit\n",
    "feedback, both of which we can use to generate recommendations. We will probably only use the implicit data if we do use\n",
    "the data in this file.\n",
    "\n",
    "We have the option of using either explicit (i.e. ratings) or implicit (i.e. interactions) data. Because the paper\n",
    "discusses the prediction of ratings, this is also what we will be doing.\n",
    "\n",
    "The following cells load the data from the files and convert them into the appropriate types. This includes parsing\n",
    "datetime strings, converting integers to numpy types, etc.\n",
    "\n",
    "## Important variables/settings\n",
    "\n",
    "- *n* determines the maximum number of rows read from any of the files.\n",
    "- *datafile*, which can be either `interactions` or `reviews`, determines the file from which the data matrix will be\n",
    "read.\n",
    "- *k* determines the number of predictions the recommender will make, and on how many predictions it will be evaluated,\n",
    "e.g. by using `Recall@k`.\n",
    "- *epochs* determines the number of epochs we will use to train the recommender."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goodreads_books_comics_graphic.json.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "89411it [00:05, 15543.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 89411 rows.\n"
     ]
    },
    {
     "data": {
      "text/plain": "         isbn text_reviews_count                            series  \\\n0                              1                                []   \n1  2205073346                  2                                []   \n2                              5  [246830, 362583, 362581, 623032]   \n3                              1                                []   \n4  0930289765                  6                 [266759, 1096220]   \n\n  country_code language_code  \\\n0           US                 \n1           US           fre   \n2           US           eng   \n3           US           eng   \n4           US         en-US   \n\n                                     popular_shelves        asin is_ebook  \\\n0  [{'count': '228', 'name': 'to-read'}, {'count'...  B00NLXQ534     true   \n1  [{'count': '2', 'name': 'bd'}, {'count': '2', ...                false   \n2  [{'count': '493', 'name': 'to-read'}, {'count'...                false   \n3  [{'count': '222', 'name': 'to-read'}, {'count'...  B06XKGGSB7     true   \n4  [{'count': '20', 'name': 'to-read'}, {'count':...                false   \n\n  average_rating kindle_asin  ... publication_month edition_information  \\\n0           4.12              ...                                         \n1           3.94              ...                 1                       \n2           4.28              ...                                         \n3           4.05  B06XKGGSB7  ...                                         \n4           4.06              ...                11                       \n\n  publication_year                                                url  \\\n0                   https://www.goodreads.com/book/show/25742454-t...   \n1             2016  https://www.goodreads.com/book/show/30128855-c...   \n2             2012  https://www.goodreads.com/book/show/13571772-c...   \n3                   https://www.goodreads.com/book/show/35452242-b...   \n4             1997  https://www.goodreads.com/book/show/707611.Sup...   \n\n                                           image_url   book_id ratings_count  \\\n0  https://s.gr-assets.com/assets/nophoto/book/11...  25742454             1   \n1  https://images.gr-assets.com/books/1462644346m...  30128855            16   \n2  https://images.gr-assets.com/books/1333287305m...  13571772            51   \n3  https://s.gr-assets.com/assets/nophoto/book/11...  35452242             6   \n4  https://images.gr-assets.com/books/1307838888m...    707611            51   \n\n    work_id                                              title  \\\n0  42749946                              The Switchblade Mamma   \n1  50558228                                            Cruelle   \n2    102217  Captain America: Winter Soldier (The Ultimate ...   \n3  54276229  Bounty Hunter 4/3: My Life in Combat from Mari...   \n4    693886                          Superman Archives, Vol. 2   \n\n                                title_without_series  \n0                              The Switchblade Mamma  \n1                                            Cruelle  \n2  Captain America: Winter Soldier (The Ultimate ...  \n3  Bounty Hunter 4/3: My Life in Combat from Mari...  \n4                          Superman Archives, Vol. 2  \n\n[5 rows x 29 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>isbn</th>\n      <th>text_reviews_count</th>\n      <th>series</th>\n      <th>country_code</th>\n      <th>language_code</th>\n      <th>popular_shelves</th>\n      <th>asin</th>\n      <th>is_ebook</th>\n      <th>average_rating</th>\n      <th>kindle_asin</th>\n      <th>...</th>\n      <th>publication_month</th>\n      <th>edition_information</th>\n      <th>publication_year</th>\n      <th>url</th>\n      <th>image_url</th>\n      <th>book_id</th>\n      <th>ratings_count</th>\n      <th>work_id</th>\n      <th>title</th>\n      <th>title_without_series</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>1</td>\n      <td>[]</td>\n      <td>US</td>\n      <td></td>\n      <td>[{'count': '228', 'name': 'to-read'}, {'count'...</td>\n      <td>B00NLXQ534</td>\n      <td>true</td>\n      <td>4.12</td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>https://www.goodreads.com/book/show/25742454-t...</td>\n      <td>https://s.gr-assets.com/assets/nophoto/book/11...</td>\n      <td>25742454</td>\n      <td>1</td>\n      <td>42749946</td>\n      <td>The Switchblade Mamma</td>\n      <td>The Switchblade Mamma</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2205073346</td>\n      <td>2</td>\n      <td>[]</td>\n      <td>US</td>\n      <td>fre</td>\n      <td>[{'count': '2', 'name': 'bd'}, {'count': '2', ...</td>\n      <td></td>\n      <td>false</td>\n      <td>3.94</td>\n      <td></td>\n      <td>...</td>\n      <td>1</td>\n      <td></td>\n      <td>2016</td>\n      <td>https://www.goodreads.com/book/show/30128855-c...</td>\n      <td>https://images.gr-assets.com/books/1462644346m...</td>\n      <td>30128855</td>\n      <td>16</td>\n      <td>50558228</td>\n      <td>Cruelle</td>\n      <td>Cruelle</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>5</td>\n      <td>[246830, 362583, 362581, 623032]</td>\n      <td>US</td>\n      <td>eng</td>\n      <td>[{'count': '493', 'name': 'to-read'}, {'count'...</td>\n      <td></td>\n      <td>false</td>\n      <td>4.28</td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td>2012</td>\n      <td>https://www.goodreads.com/book/show/13571772-c...</td>\n      <td>https://images.gr-assets.com/books/1333287305m...</td>\n      <td>13571772</td>\n      <td>51</td>\n      <td>102217</td>\n      <td>Captain America: Winter Soldier (The Ultimate ...</td>\n      <td>Captain America: Winter Soldier (The Ultimate ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>1</td>\n      <td>[]</td>\n      <td>US</td>\n      <td>eng</td>\n      <td>[{'count': '222', 'name': 'to-read'}, {'count'...</td>\n      <td>B06XKGGSB7</td>\n      <td>true</td>\n      <td>4.05</td>\n      <td>B06XKGGSB7</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>https://www.goodreads.com/book/show/35452242-b...</td>\n      <td>https://s.gr-assets.com/assets/nophoto/book/11...</td>\n      <td>35452242</td>\n      <td>6</td>\n      <td>54276229</td>\n      <td>Bounty Hunter 4/3: My Life in Combat from Mari...</td>\n      <td>Bounty Hunter 4/3: My Life in Combat from Mari...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0930289765</td>\n      <td>6</td>\n      <td>[266759, 1096220]</td>\n      <td>US</td>\n      <td>en-US</td>\n      <td>[{'count': '20', 'name': 'to-read'}, {'count':...</td>\n      <td></td>\n      <td>false</td>\n      <td>4.06</td>\n      <td></td>\n      <td>...</td>\n      <td>11</td>\n      <td></td>\n      <td>1997</td>\n      <td>https://www.goodreads.com/book/show/707611.Sup...</td>\n      <td>https://images.gr-assets.com/books/1307838888m...</td>\n      <td>707611</td>\n      <td>51</td>\n      <td>693886</td>\n      <td>Superman Archives, Vol. 2</td>\n      <td>Superman Archives, Vol. 2</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 29 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goodreads_reviews_comics_graphic.json.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "542338it [00:06, 89042.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 542338 rows.\n"
     ]
    },
    {
     "data": {
      "text/plain": "                            user_id   book_id  \\\n0  dc3763cdb9b2cae805882878eebb6a32  18471619   \n1  bafc2d50014200cda7cb2b6acd60cd73   6315584   \n2  bafc2d50014200cda7cb2b6acd60cd73  29847729   \n3  bafc2d50014200cda7cb2b6acd60cd73  18454118   \n4  bafc2d50014200cda7cb2b6acd60cd73   2239435   \n\n                          review_id  rating  \\\n0  66b2ba840f9bd36d6d27f46136fe4772       3   \n1  72f1229aba5a88f9e72f0dcdc007dd22       4   \n2  a75309355f8662caaa5e2c92ab693d3f       4   \n3  c3cc5a3e1d6b6c9cf1c044f306c8e752       5   \n4  cc444be37ab0a42bfb4dd818cb5edd10       4   \n\n                                         review_text  \\\n0  Sherlock Holmes and the Vampires of London \\n ...   \n1  I've never really liked Spider-Man. I am, howe...   \n2  A very quick introduction, this is coming out ...   \n3  I've been waiting so long for this. I first st...   \n4  The only thing more entertaining than this boo...   \n\n                       date_added                    date_updated  \\\n0  Thu Dec 05 10:44:25 -0800 2013  Thu Dec 05 10:45:15 -0800 2013   \n1  Wed Aug 10 06:06:48 -0700 2016  Fri Aug 12 08:49:54 -0700 2016   \n2  Thu Apr 21 07:44:00 -0700 2016  Thu Apr 21 07:59:28 -0700 2016   \n3  Mon Mar 03 17:45:56 -0800 2014  Mon Mar 03 17:54:11 -0800 2014   \n4  Wed Apr 03 12:37:48 -0700 2013  Wed Apr 03 13:03:36 -0700 2013   \n\n                          read_at                      started_at  n_votes  \\\n0  Tue Nov 05 00:00:00 -0800 2013                                        0   \n1  Fri Aug 12 08:49:54 -0700 2016  Wed Aug 10 00:00:00 -0700 2016        0   \n2  Thu Apr 21 07:59:28 -0700 2016  Thu Apr 21 00:00:00 -0700 2016        0   \n3  Sat Mar 01 00:00:00 -0800 2014  Sat Mar 01 00:00:00 -0800 2014        1   \n4  Wed Apr 03 13:03:36 -0700 2013                                        0   \n\n   n_comments  \n0           0  \n1           0  \n2           0  \n3           0  \n4           0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>book_id</th>\n      <th>review_id</th>\n      <th>rating</th>\n      <th>review_text</th>\n      <th>date_added</th>\n      <th>date_updated</th>\n      <th>read_at</th>\n      <th>started_at</th>\n      <th>n_votes</th>\n      <th>n_comments</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dc3763cdb9b2cae805882878eebb6a32</td>\n      <td>18471619</td>\n      <td>66b2ba840f9bd36d6d27f46136fe4772</td>\n      <td>3</td>\n      <td>Sherlock Holmes and the Vampires of London \\n ...</td>\n      <td>Thu Dec 05 10:44:25 -0800 2013</td>\n      <td>Thu Dec 05 10:45:15 -0800 2013</td>\n      <td>Tue Nov 05 00:00:00 -0800 2013</td>\n      <td></td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bafc2d50014200cda7cb2b6acd60cd73</td>\n      <td>6315584</td>\n      <td>72f1229aba5a88f9e72f0dcdc007dd22</td>\n      <td>4</td>\n      <td>I've never really liked Spider-Man. I am, howe...</td>\n      <td>Wed Aug 10 06:06:48 -0700 2016</td>\n      <td>Fri Aug 12 08:49:54 -0700 2016</td>\n      <td>Fri Aug 12 08:49:54 -0700 2016</td>\n      <td>Wed Aug 10 00:00:00 -0700 2016</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bafc2d50014200cda7cb2b6acd60cd73</td>\n      <td>29847729</td>\n      <td>a75309355f8662caaa5e2c92ab693d3f</td>\n      <td>4</td>\n      <td>A very quick introduction, this is coming out ...</td>\n      <td>Thu Apr 21 07:44:00 -0700 2016</td>\n      <td>Thu Apr 21 07:59:28 -0700 2016</td>\n      <td>Thu Apr 21 07:59:28 -0700 2016</td>\n      <td>Thu Apr 21 00:00:00 -0700 2016</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>bafc2d50014200cda7cb2b6acd60cd73</td>\n      <td>18454118</td>\n      <td>c3cc5a3e1d6b6c9cf1c044f306c8e752</td>\n      <td>5</td>\n      <td>I've been waiting so long for this. I first st...</td>\n      <td>Mon Mar 03 17:45:56 -0800 2014</td>\n      <td>Mon Mar 03 17:54:11 -0800 2014</td>\n      <td>Sat Mar 01 00:00:00 -0800 2014</td>\n      <td>Sat Mar 01 00:00:00 -0800 2014</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bafc2d50014200cda7cb2b6acd60cd73</td>\n      <td>2239435</td>\n      <td>cc444be37ab0a42bfb4dd818cb5edd10</td>\n      <td>4</td>\n      <td>The only thing more entertaining than this boo...</td>\n      <td>Wed Apr 03 12:37:48 -0700 2013</td>\n      <td>Wed Apr 03 13:03:36 -0700 2013</td>\n      <td>Wed Apr 03 13:03:36 -0700 2013</td>\n      <td></td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = \"data/\"\n",
    "books = \"goodreads_books_comics_graphic.json.gz\"\n",
    "interactions = \"goodreads_interactions_comics_graphic.json.gz\"\n",
    "reviews = \"goodreads_reviews_comics_graphic.json.gz\"\n",
    "datasets = {books: None, reviews: None}  # interactions: None,\n",
    "\n",
    "n = None\n",
    "datafile = reviews\n",
    "k = 10\n",
    "epochs = 20\n",
    "\n",
    "for filename in datasets.keys():\n",
    "    print(filename)\n",
    "    datasets[filename] = parse_json(data_path + filename, n)\n",
    "    display(datasets[filename].head(5))\n",
    "\n",
    "books_df = datasets[books][[\"book_id\", \"title\"]].copy()\n",
    "interactions_df = datasets[datafile][[\"user_id\", \"book_id\", \"rating\", \"date_updated\"]].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "format_str = \"%a %b %d %H:%M:%S %z %Y\"\n",
    "interactions_df[\"date_updated\"] = pd.to_datetime(interactions_df[\"date_updated\"], format=format_str)\n",
    "\n",
    "books_df[\"book_id\"] = books_df[\"book_id\"].astype(\"int64\")\n",
    "interactions_df[\"book_id\"] = interactions_df[\"book_id\"].astype(\"int64\")\n",
    "\n",
    "interactions_df = interactions_df.sort_values(by=[\"user_id\", \"date_updated\"], ascending=[True, True])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing\n",
    "\n",
    "We apply the following preprocessing steps:\n",
    "\n",
    "- Reconsumption item removal, although there aren't many (or even none at all) of these in the dataset.\n",
    "\n",
    "- Infrequent item removal; we remove any items that have less than a certain number (5) of interactions/ratings.\n",
    "\n",
    "- Infrequent user removal; we remove users with less that the same certain number (5) of interactions/ratings."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                                 user_id   book_id  rating  \\\n498184  00009e46d18f223a82b22da38586b605  23546829       3   \n54004   000192962b87d560f00b06fdcbd71681  30025791       5   \n541427  0003a8eb2989503d03ad7ca701898a48  23479604       0   \n541426  0003a8eb2989503d03ad7ca701898a48  15780398       2   \n541425  0003a8eb2989503d03ad7ca701898a48  22738008       0   \n255717  0005a08accd53b1e19c52109a1f478cb   1472402       5   \n255716  0005a08accd53b1e19c52109a1f478cb    119162       4   \n255715  0005a08accd53b1e19c52109a1f478cb   3285607       5   \n255714  0005a08accd53b1e19c52109a1f478cb     59960       0   \n255713  0005a08accd53b1e19c52109a1f478cb    107037       3   \n\n                     date_updated  \n498184  2016-01-15 19:31:35-08:00  \n54004   2017-01-28 09:56:08-08:00  \n541427  2015-05-29 08:00:12-07:00  \n541426  2015-05-29 08:02:05-07:00  \n541425  2015-05-29 08:04:06-07:00  \n255717  2007-09-16 21:21:34-07:00  \n255716  2008-04-11 01:09:21-07:00  \n255715  2008-05-12 19:27:12-07:00  \n255714  2008-09-09 18:23:53-07:00  \n255713  2011-07-20 10:58:49-07:00  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>book_id</th>\n      <th>rating</th>\n      <th>date_updated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>498184</th>\n      <td>00009e46d18f223a82b22da38586b605</td>\n      <td>23546829</td>\n      <td>3</td>\n      <td>2016-01-15 19:31:35-08:00</td>\n    </tr>\n    <tr>\n      <th>54004</th>\n      <td>000192962b87d560f00b06fdcbd71681</td>\n      <td>30025791</td>\n      <td>5</td>\n      <td>2017-01-28 09:56:08-08:00</td>\n    </tr>\n    <tr>\n      <th>541427</th>\n      <td>0003a8eb2989503d03ad7ca701898a48</td>\n      <td>23479604</td>\n      <td>0</td>\n      <td>2015-05-29 08:00:12-07:00</td>\n    </tr>\n    <tr>\n      <th>541426</th>\n      <td>0003a8eb2989503d03ad7ca701898a48</td>\n      <td>15780398</td>\n      <td>2</td>\n      <td>2015-05-29 08:02:05-07:00</td>\n    </tr>\n    <tr>\n      <th>541425</th>\n      <td>0003a8eb2989503d03ad7ca701898a48</td>\n      <td>22738008</td>\n      <td>0</td>\n      <td>2015-05-29 08:04:06-07:00</td>\n    </tr>\n    <tr>\n      <th>255717</th>\n      <td>0005a08accd53b1e19c52109a1f478cb</td>\n      <td>1472402</td>\n      <td>5</td>\n      <td>2007-09-16 21:21:34-07:00</td>\n    </tr>\n    <tr>\n      <th>255716</th>\n      <td>0005a08accd53b1e19c52109a1f478cb</td>\n      <td>119162</td>\n      <td>4</td>\n      <td>2008-04-11 01:09:21-07:00</td>\n    </tr>\n    <tr>\n      <th>255715</th>\n      <td>0005a08accd53b1e19c52109a1f478cb</td>\n      <td>3285607</td>\n      <td>5</td>\n      <td>2008-05-12 19:27:12-07:00</td>\n    </tr>\n    <tr>\n      <th>255714</th>\n      <td>0005a08accd53b1e19c52109a1f478cb</td>\n      <td>59960</td>\n      <td>0</td>\n      <td>2008-09-09 18:23:53-07:00</td>\n    </tr>\n    <tr>\n      <th>255713</th>\n      <td>0005a08accd53b1e19c52109a1f478cb</td>\n      <td>107037</td>\n      <td>3</td>\n      <td>2011-07-20 10:58:49-07:00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 59347\n",
      "Number of unique items: 89311\n",
      "542338 initial rows\n",
      "542338 rows after removing reconsumption items\n",
      "367781 rows after removing infrequent items and users\n",
      "Number of unique users: 16326\n",
      "Number of unique items: 19029\n"
     ]
    },
    {
     "data": {
      "text/plain": "                             user_id   book_id  rating  \\\n5   0005a08accd53b1e19c52109a1f478cb   1472402       5   \n7   0005a08accd53b1e19c52109a1f478cb   3285607       5   \n8   0005a08accd53b1e19c52109a1f478cb     59960       0   \n13  0006260f85929db85eddee3a0bd0e504  29869650       4   \n14  0006260f85929db85eddee3a0bd0e504  29521992       5   \n20  0008931c0cde961e9c802c5a58196d23   6081685       5   \n21  0008931c0cde961e9c802c5a58196d23   7311068       5   \n22  0008931c0cde961e9c802c5a58196d23   6690979       5   \n24  0008931c0cde961e9c802c5a58196d23   6599344       5   \n25  0008931c0cde961e9c802c5a58196d23   6372263       5   \n\n                 date_updated  \n5   2007-09-16 21:21:34-07:00  \n7   2008-05-12 19:27:12-07:00  \n8   2008-09-09 18:23:53-07:00  \n13  2016-05-11 04:53:09-07:00  \n14  2016-10-07 05:08:26-07:00  \n20  2013-03-09 07:02:48-08:00  \n21  2013-03-09 07:03:42-08:00  \n22  2013-03-09 07:05:26-08:00  \n24  2014-01-26 10:16:17-08:00  \n25  2014-01-26 10:19:19-08:00  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>book_id</th>\n      <th>rating</th>\n      <th>date_updated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>0005a08accd53b1e19c52109a1f478cb</td>\n      <td>1472402</td>\n      <td>5</td>\n      <td>2007-09-16 21:21:34-07:00</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0005a08accd53b1e19c52109a1f478cb</td>\n      <td>3285607</td>\n      <td>5</td>\n      <td>2008-05-12 19:27:12-07:00</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0005a08accd53b1e19c52109a1f478cb</td>\n      <td>59960</td>\n      <td>0</td>\n      <td>2008-09-09 18:23:53-07:00</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0006260f85929db85eddee3a0bd0e504</td>\n      <td>29869650</td>\n      <td>4</td>\n      <td>2016-05-11 04:53:09-07:00</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0006260f85929db85eddee3a0bd0e504</td>\n      <td>29521992</td>\n      <td>5</td>\n      <td>2016-10-07 05:08:26-07:00</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0008931c0cde961e9c802c5a58196d23</td>\n      <td>6081685</td>\n      <td>5</td>\n      <td>2013-03-09 07:02:48-08:00</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0008931c0cde961e9c802c5a58196d23</td>\n      <td>7311068</td>\n      <td>5</td>\n      <td>2013-03-09 07:03:42-08:00</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0008931c0cde961e9c802c5a58196d23</td>\n      <td>6690979</td>\n      <td>5</td>\n      <td>2013-03-09 07:05:26-08:00</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0008931c0cde961e9c802c5a58196d23</td>\n      <td>6599344</td>\n      <td>5</td>\n      <td>2014-01-26 10:16:17-08:00</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0008931c0cde961e9c802c5a58196d23</td>\n      <td>6372263</td>\n      <td>5</td>\n      <td>2014-01-26 10:19:19-08:00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess(df: pd.DataFrame, min_support: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Removes reconsumption items, items that have less than `min_support` interactions, and users that have less than\n",
    "    `min_support` interactions. In some cases, removing an infrequent item may turn a frequent user into an infrequent\n",
    "    one, and vice versa. In these cases, we don't remove the now infrequent user/item, we only consider the original\n",
    "    frequency. As such, the preprocessed dataset may contain some users and items that don't reach the minimum support\n",
    "    limit.\n",
    "    \"\"\"\n",
    "    print(df.shape[0], \"initial rows\")\n",
    "    # Drop reconsumption items\n",
    "    df = df.drop_duplicates(subset=[\"user_id\", \"book_id\"])\n",
    "    print(df.shape[0], \"rows after removing reconsumption items\")\n",
    "    # Compute user and item counts\n",
    "    g1 = df.groupby(\"book_id\", as_index=False)[\"user_id\"].size()\n",
    "    g1 = g1.rename({\"size\": \"users_per_item\"}, axis=\"columns\")\n",
    "    g2 = df.groupby(\"user_id\", as_index=False)[\"book_id\"].size()\n",
    "    g2 = g2.rename({\"size\": \"items_per_user\"}, axis=\"columns\")\n",
    "    df = pd.merge(df, g1, how=\"left\", on=[\"book_id\"])\n",
    "    df = pd.merge(df, g2, how=\"left\", on=[\"user_id\"])\n",
    "    # Drop items and users with less than `min_support` interactions\n",
    "    df = df[(df[\"users_per_item\"] >= min_support) & (df[\"items_per_user\"] >= min_support)]\n",
    "    print(df.shape[0], \"rows after removing infrequent items and users\")\n",
    "    df.drop(columns=[\"users_per_item\", \"items_per_user\"], inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "display(interactions_df.head(10))\n",
    "print(f\"Number of unique users:\", interactions_df[\"user_id\"].nunique())\n",
    "print(f\"Number of unique items:\", interactions_df[\"book_id\"].nunique())\n",
    "processed_df = preprocess(interactions_df)\n",
    "print(f\"Number of unique users:\", processed_df[\"user_id\"].nunique())\n",
    "print(f\"Number of unique items:\", processed_df[\"book_id\"].nunique())\n",
    "display(processed_df.head(10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 367781/367781 [00:00<00:00, 1218634.49it/s]\n",
      "100%|██████████| 367781/367781 [00:00<00:00, 1227933.50it/s]\n",
      "100%|██████████| 89411/89411 [00:00<00:00, 1148308.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "    book_id                                              title  book_id_int\n0  25742454                              The Switchblade Mamma           -1\n1  30128855                                            Cruelle           -1\n2  13571772  Captain America: Winter Soldier (The Ultimate ...           -1\n3  35452242  Bounty Hunter 4/3: My Life in Combat from Mari...           -1\n4    707611                          Superman Archives, Vol. 2           -1\n5   2250580                            A.I. Revolution, Vol. 1         7820\n6  27036536                              War Stories, Volume 3           -1\n7  27036537                                 Crossed, Volume 15           -1\n8  27036538  Crossed + One Hundred, Volume 2 (Crossed +100 #2)           -1\n9  27036539                              War Stories, Volume 4           -1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>book_id</th>\n      <th>title</th>\n      <th>book_id_int</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>25742454</td>\n      <td>The Switchblade Mamma</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>30128855</td>\n      <td>Cruelle</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13571772</td>\n      <td>Captain America: Winter Soldier (The Ultimate ...</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35452242</td>\n      <td>Bounty Hunter 4/3: My Life in Combat from Mari...</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>707611</td>\n      <td>Superman Archives, Vol. 2</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2250580</td>\n      <td>A.I. Revolution, Vol. 1</td>\n      <td>7820</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>27036536</td>\n      <td>War Stories, Volume 3</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>27036537</td>\n      <td>Crossed, Volume 15</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>27036538</td>\n      <td>Crossed + One Hundred, Volume 2 (Crossed +100 #2)</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>27036539</td>\n      <td>War Stories, Volume 4</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "    user_id  item_id                   datetime  rating\n5         0        0  2007-09-16 21:21:34-07:00       5\n7         0        1  2008-05-12 19:27:12-07:00       5\n8         0        2  2008-09-09 18:23:53-07:00       0\n13        1        3  2016-05-11 04:53:09-07:00       4\n14        1        4  2016-10-07 05:08:26-07:00       5\n20        2        5  2013-03-09 07:02:48-08:00       5\n21        2        6  2013-03-09 07:03:42-08:00       5\n22        2        7  2013-03-09 07:05:26-08:00       5\n24        2        8  2014-01-26 10:16:17-08:00       5\n25        2        9  2014-01-26 10:19:19-08:00       5",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>datetime</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>2007-09-16 21:21:34-07:00</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2008-05-12 19:27:12-07:00</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>2</td>\n      <td>2008-09-09 18:23:53-07:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1</td>\n      <td>3</td>\n      <td>2016-05-11 04:53:09-07:00</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1</td>\n      <td>4</td>\n      <td>2016-10-07 05:08:26-07:00</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>2</td>\n      <td>5</td>\n      <td>2013-03-09 07:02:48-08:00</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>2</td>\n      <td>6</td>\n      <td>2013-03-09 07:03:42-08:00</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>2</td>\n      <td>7</td>\n      <td>2013-03-09 07:05:26-08:00</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>2</td>\n      <td>8</td>\n      <td>2014-01-26 10:16:17-08:00</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>2</td>\n      <td>9</td>\n      <td>2014-01-26 10:19:19-08:00</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def apply_consecutive_mapping(dataframe: pd.DataFrame, column: str, new_column: str, *additional: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Generates a consecutive ID column for the values of an existing column. Also adds this column to additional data\n",
    "    frames with the exact same mapping of old ID to new (consecutive) ID.\n",
    "    \"\"\"\n",
    "    ids = {}\n",
    "\n",
    "    def map_to_consecutive_ids(uuid: Union[int, np.int64]) -> int:\n",
    "        \"\"\"\n",
    "        To be used with `pd.Dataframe.apply()` or `pd.Dataframe.progress_apply()`; returns a unique ID per distinct\n",
    "        value.\n",
    "        \"\"\"\n",
    "        if uuid not in ids:\n",
    "            ids[uuid] = len(ids)\n",
    "        return ids[uuid]\n",
    "\n",
    "    dataframe[new_column] = dataframe[column].progress_apply(map_to_consecutive_ids)\n",
    "    for frame in additional:\n",
    "        frame[new_column] = frame[column].progress_apply(lambda old_id: ids.get(old_id, -1))\n",
    "\n",
    "\n",
    "apply_consecutive_mapping(processed_df, \"user_id\", \"user_id_int\")\n",
    "apply_consecutive_mapping(processed_df, \"book_id\", \"book_id_int\", books_df)\n",
    "processed_df = processed_df[[\"user_id_int\", \"book_id_int\", \"date_updated\", \"rating\"]]\n",
    "processed_df = processed_df.rename(\n",
    "    columns={\"user_id_int\": \"user_id\", \"book_id_int\": \"item_id\", \"date_updated\": \"datetime\"})\n",
    "\n",
    "display(books_df.head(10))\n",
    "display(processed_df.head(10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def split(items: list[int], percentage_train: float) -> pd.Series:\n",
    "    nr_train_items = int(len(items) * percentage_train)\n",
    "    return pd.Series((items[: nr_train_items], items[nr_train_items:]))\n",
    "\n",
    "\n",
    "sessions_df = processed_df.groupby(by=\"user_id\", as_index=False)[[\"item_id\", \"datetime\", \"rating\"]].agg(list)\n",
    "display(sessions_df.head(5))\n",
    "\n",
    "percentage_train = 0.8\n",
    "sessions_df[[\"item_id_history\", \"item_id_future\"]] = sessions_df[\"item_id\"].progress_apply(split,\n",
    "                                                                                           args=(percentage_train,))\n",
    "sessions_df[[\"rating_history\", \"rating_future\"]] = sessions_df[\"rating\"].progress_apply(split, args=(percentage_train,))\n",
    "display(sessions_df.head(5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id                                           item_id  \\\n0        0                                         [0, 1, 2]   \n1        1                                            [3, 4]   \n2        2       [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]   \n3        3                              [17, 18, 19, 20, 21]   \n4        4  [22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]   \n\n                                            datetime  \\\n0  [2007-09-16 21:21:34-07:00, 2008-05-12 19:27:1...   \n1  [2016-05-11 04:53:09-07:00, 2016-10-07 05:08:2...   \n2  [2013-03-09 07:02:48-08:00, 2013-03-09 07:03:4...   \n3  [2017-04-04 12:19:56-07:00, 2017-04-06 10:10:5...   \n4  [2016-03-04 06:02:24-08:00, 2016-07-23 01:02:4...   \n\n                                 rating  \n0                             [5, 5, 0]  \n1                                [4, 5]  \n2  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]  \n3                       [5, 5, 5, 5, 5]  \n4  [3, 4, 3, 3, 3, 2, 1, 3, 3, 3, 4, 3]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>datetime</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>[0, 1, 2]</td>\n      <td>[2007-09-16 21:21:34-07:00, 2008-05-12 19:27:1...</td>\n      <td>[5, 5, 0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>[3, 4]</td>\n      <td>[2016-05-11 04:53:09-07:00, 2016-10-07 05:08:2...</td>\n      <td>[4, 5]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]</td>\n      <td>[2013-03-09 07:02:48-08:00, 2013-03-09 07:03:4...</td>\n      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>[17, 18, 19, 20, 21]</td>\n      <td>[2017-04-04 12:19:56-07:00, 2017-04-06 10:10:5...</td>\n      <td>[5, 5, 5, 5, 5]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>[22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]</td>\n      <td>[2016-03-04 06:02:24-08:00, 2016-07-23 01:02:4...</td>\n      <td>[3, 4, 3, 3, 3, 2, 1, 3, 3, 3, 4, 3]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16326/16326 [00:02<00:00, 7376.45it/s] \n",
      "100%|██████████| 16326/16326 [00:02<00:00, 6922.74it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": "   user_id                                           item_id  \\\n0        0                                         [0, 1, 2]   \n1        1                                            [3, 4]   \n2        2       [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]   \n3        3                              [17, 18, 19, 20, 21]   \n4        4  [22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]   \n\n                                            datetime  \\\n0  [2007-09-16 21:21:34-07:00, 2008-05-12 19:27:1...   \n1  [2016-05-11 04:53:09-07:00, 2016-10-07 05:08:2...   \n2  [2013-03-09 07:02:48-08:00, 2013-03-09 07:03:4...   \n3  [2017-04-04 12:19:56-07:00, 2017-04-06 10:10:5...   \n4  [2016-03-04 06:02:24-08:00, 2016-07-23 01:02:4...   \n\n                                 rating                       item_id_history  \\\n0                             [5, 5, 0]                                [0, 1]   \n1                                [4, 5]                                   [3]   \n2  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]       [5, 6, 7, 8, 9, 10, 11, 12, 13]   \n3                       [5, 5, 5, 5, 5]                      [17, 18, 19, 20]   \n4  [3, 4, 3, 3, 3, 2, 1, 3, 3, 3, 4, 3]  [22, 23, 24, 25, 26, 27, 28, 29, 30]   \n\n  item_id_future               rating_history rating_future  \n0            [2]                       [5, 5]           [0]  \n1            [4]                          [4]           [5]  \n2   [14, 15, 16]  [5, 5, 5, 5, 5, 5, 5, 5, 5]     [5, 5, 5]  \n3           [21]                 [5, 5, 5, 5]           [5]  \n4   [31, 32, 33]  [3, 4, 3, 3, 3, 2, 1, 3, 3]     [3, 4, 3]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>datetime</th>\n      <th>rating</th>\n      <th>item_id_history</th>\n      <th>item_id_future</th>\n      <th>rating_history</th>\n      <th>rating_future</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>[0, 1, 2]</td>\n      <td>[2007-09-16 21:21:34-07:00, 2008-05-12 19:27:1...</td>\n      <td>[5, 5, 0]</td>\n      <td>[0, 1]</td>\n      <td>[2]</td>\n      <td>[5, 5]</td>\n      <td>[0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>[3, 4]</td>\n      <td>[2016-05-11 04:53:09-07:00, 2016-10-07 05:08:2...</td>\n      <td>[4, 5]</td>\n      <td>[3]</td>\n      <td>[4]</td>\n      <td>[4]</td>\n      <td>[5]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]</td>\n      <td>[2013-03-09 07:02:48-08:00, 2013-03-09 07:03:4...</td>\n      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]</td>\n      <td>[5, 6, 7, 8, 9, 10, 11, 12, 13]</td>\n      <td>[14, 15, 16]</td>\n      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5]</td>\n      <td>[5, 5, 5]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>[17, 18, 19, 20, 21]</td>\n      <td>[2017-04-04 12:19:56-07:00, 2017-04-06 10:10:5...</td>\n      <td>[5, 5, 5, 5, 5]</td>\n      <td>[17, 18, 19, 20]</td>\n      <td>[21]</td>\n      <td>[5, 5, 5, 5]</td>\n      <td>[5]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>[22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]</td>\n      <td>[2016-03-04 06:02:24-08:00, 2016-07-23 01:02:4...</td>\n      <td>[3, 4, 3, 3, 3, 2, 1, 3, 3, 3, 4, 3]</td>\n      <td>[22, 23, 24, 25, 26, 27, 28, 29, 30]</td>\n      <td>[31, 32, 33]</td>\n      <td>[3, 4, 3, 3, 3, 2, 1, 3, 3]</td>\n      <td>[3, 4, 3]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def create_sparse_matrix(dataframe: pd.DataFrame, item_id_column: str, value_column: str = None,\n",
    "                         shape: tuple[int, int] = None) -> sparse.csr_matrix:\n",
    "    \"\"\"\n",
    "    Creates a sparse matrix from the data in `dataframe`.\n",
    "    \"\"\"\n",
    "    # Flatten the dataframe\n",
    "    user_ids = []\n",
    "    item_ids = []\n",
    "    values = []\n",
    "    for index, row in dataframe.iterrows():\n",
    "        user_ids.extend([row[\"user_id\"]] * len(row[item_id_column]))\n",
    "        item_ids.extend(row[item_id_column])\n",
    "        if value_column is not None:\n",
    "            values.extend(row[value_column])\n",
    "    if value_column is None:\n",
    "        values = np.ones(len(user_ids))\n",
    "    # Create the CSR matrix\n",
    "    return sparse.csr_matrix((values, (user_ids, item_ids)), shape=shape, dtype=np.int32)\n",
    "\n",
    "\n",
    "shape = (processed_df[\"user_id\"].max() + 1, processed_df[\"item_id\"].max() + 1)\n",
    "train = create_sparse_matrix(sessions_df, \"item_id_history\", \"rating_history\", shape)\n",
    "true = create_sparse_matrix(sessions_df, \"item_id_future\", \"rating_future\", shape)\n",
    "# train = create_sparse_matrix(sessions_df, \"item_id_history\", None, shape)\n",
    "# true = create_sparse_matrix(sessions_df, \"item_id_future\", None, shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation\n",
    "\n",
    "The evaluation metrics we will be using are the following:\n",
    "\n",
    "- Recall @ 10: the percentage of users where the top-10 recommendations are relevant.\n",
    "\n",
    "- NDCG @ 10: similar to recall but the sum of the hits is weighted by the place in the top 10.\n",
    "\n",
    "- Qualitative results, i.e. examples of the recommendations."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def sparse_invert_nonzero(a: sparse.csr_matrix) -> sparse.csr_matrix:\n",
    "    inverse = a.copy()\n",
    "    inverse.data = 1 / inverse.data\n",
    "    return inverse\n",
    "\n",
    "\n",
    "def sparse_divide_nonzero(a: sparse.csr_matrix, b: sparse.csr_matrix) -> sparse.csr_matrix:\n",
    "    return a.multiply(sparse_invert_nonzero(b))\n",
    "\n",
    "\n",
    "def compute_recall(true: sparse.csr_matrix, predicted: sparse.csr_matrix) -> float:\n",
    "    scores = sparse.lil_matrix(predicted.shape)\n",
    "    scores[predicted.multiply(true).astype(bool)] = 1\n",
    "    scores = sparse_divide_nonzero(scores.tocsr(), sparse.csr_matrix(true.sum(axis=1))).sum(axis=1)\n",
    "    return scores.mean()\n",
    "\n",
    "# recall = compute_recall(true, predicted)\n",
    "# print(f\"Recall @ {k}: {recall:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RBM-based recommender"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "76c9641daed74a62aba59b067e7a3216"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/327 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c7397d8119be450db50be56213f7c6c2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : 6.908366680145264\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/327 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2641874ece234e0ba1420b631b6d8486"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 : 7.3664703369140625\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/327 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "acbef42236a443e28f6f2cf77ea8d772"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 : 6.983094215393066\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/327 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5d1b338986644916ba0abf83ed7234bc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 : 6.5223565101623535\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/327 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e0a9d9077ad04d4ca59ea447ded58ec9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 : 6.208868980407715\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/327 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cc350ab6c9db40b8921d50279dab5a31"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 : 5.972803592681885\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/327 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8cd0c02e21ac454fa4c14636f93ab874"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 : 5.760688304901123\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/327 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24c3579386e147ab8b4152ea95845696"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 : 5.593102931976318\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/327 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce97c7db9feb47f99e8acb4dd6650f3c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 : 5.4447503089904785\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/327 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d67b3efa41b43b2bb2a9ec344741d4f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 5.2967658042907715\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "\n",
    "class RBM:\n",
    "\n",
    "    def __init__(self, nr_visible: int, nr_hidden: int, learning_rate: float) -> None:\n",
    "        self.weights = torch.randn(nr_visible, nr_hidden).to(device)\n",
    "        self.bias_items = torch.randn(nr_visible).to(device)\n",
    "        self.bias_features = torch.randn(nr_hidden).to(device)\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def prob_hidden(self, visible: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.sigmoid(visible @ self.weights + self.bias_features)\n",
    "\n",
    "    def prob_visible(self, hidden: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.sigmoid(hidden @ self.weights.t() + self.bias_items)\n",
    "\n",
    "    @staticmethod\n",
    "    def sample(probabilities: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.bernoulli(probabilities)\n",
    "\n",
    "    def update(self, visible_0: torch.Tensor, visible_k: torch.Tensor, prob_hidden_0: torch.Tensor,\n",
    "               prob_hidden_k: torch.Tensor) -> None:\n",
    "        self.weights += self.learning_rate * (visible_0.t() @ prob_hidden_0 - visible_k.t() @ prob_hidden_k)\n",
    "        self.bias_items += self.learning_rate * (visible_0 - visible_k).sum(0)\n",
    "        self.bias_features += self.learning_rate * (prob_hidden_0 - prob_hidden_k).sum(0)\n",
    "\n",
    "    def fit(self, visible_0: torch.Tensor, sampling_iterations: int = 1) -> torch.Tensor:\n",
    "        visible_k = visible_0\n",
    "        for _ in range(sampling_iterations):\n",
    "            hidden_k = self.sample(self.prob_hidden(visible_k))\n",
    "            visible_k = self.sample(self.prob_visible(hidden_k))\n",
    "            visible_k[visible_0 < 0] = visible_0[visible_0 < 0]\n",
    "        prob_hidden_0 = self.sample(self.prob_hidden(visible_0))\n",
    "        prob_hidden_k = self.sample(self.prob_hidden(visible_k))\n",
    "        self.update(visible_0, visible_k, prob_hidden_0, prob_hidden_k)\n",
    "        return visible_k\n",
    "\n",
    "    def predict_(self, data: torch.Tensor, k: int = 10) -> tuple[np.ndarray, np.ndarray]:\n",
    "        hidden = self.sample(self.prob_hidden(data))\n",
    "        probabilities = self.prob_visible(hidden)\n",
    "        probabilities[data >= 0] = 0\n",
    "        probabilities = probabilities.cpu().numpy()\n",
    "        items = np.argpartition(-probabilities, k, 1)[:, :k]\n",
    "        scores = probabilities[np.repeat(np.arange(data.shape[0]), k), items.flatten()]\n",
    "        return items, scores.reshape(items.shape)\n",
    "\n",
    "    def predict(self, data: sparse.csr_matrix, k: int = 10, batch_size: int = 1024) -> sparse.csr_matrix:\n",
    "        user_ids = []\n",
    "        item_ids = []\n",
    "        scores = []\n",
    "        for batch_start in trange(0, data.shape[0], batch_size):\n",
    "            batch = self.convert(data[batch_start : batch_start + batch_size])\n",
    "            predictions, prediction_scores = self.predict_(batch, k)\n",
    "            user_ids.extend(np.repeat(range(batch_start, batch_start + batch_size), k))\n",
    "            item_ids.extend(predictions.flatten())\n",
    "            scores.extend(prediction_scores.flatten())\n",
    "        return sparse.csr_matrix((scores, (user_ids, item_ids)), shape=data.shape)\n",
    "\n",
    "    @staticmethod\n",
    "    def convert(data: sparse.csr_matrix) -> torch.Tensor:\n",
    "        tensor = torch.Tensor(data.toarray()).to(device)\n",
    "        tensor[tensor == 0] = -1\n",
    "        tensor[tensor == 1] = 0\n",
    "        tensor[tensor == 2] = 0\n",
    "        tensor[tensor >= 3] = 1\n",
    "        return tensor\n",
    "\n",
    "\n",
    "rbm = RBM(train.shape[1], 1000, 0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 50\n",
    "for epoch in tqdm(range(epochs), leave=False):\n",
    "    train_loss = 0\n",
    "    for batch_start in trange(0, train.shape[0], batch_size, leave=False):\n",
    "        batch = rbm.convert(train[batch_start: batch_start + batch_size])\n",
    "        reconstruction = rbm.fit(batch)\n",
    "        train_loss += torch.abs(batch[batch >= 0] - reconstruction[batch >= 0]).sum()\n",
    "    tqdm.write(f\"\\rEpoch {epoch + 1:<2}: {(train_loss / train.shape[0]).item()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/16326 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "298ccfb1b93045a88285c279739630a3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 35)\t0.97747767\n",
      "  (0, 47)\t0.9815423\n",
      "  (0, 59)\t0.9803269\n",
      "  (0, 72)\t0.9879474\n",
      "  (0, 144)\t0.9740559\n",
      "  (0, 182)\t0.9782261\n",
      "  (0, 3144)\t0.9757077\n",
      "  (0, 14975)\t0.9787143\n",
      "  (0, 16505)\t0.97459\n",
      "  (0, 17928)\t0.9862346\n",
      "  (1, 35)\t0.97747767\n",
      "  (1, 47)\t0.9815423\n",
      "  (1, 59)\t0.9803269\n",
      "  (1, 72)\t0.9879474\n",
      "  (1, 144)\t0.9740559\n",
      "  (1, 182)\t0.9782261\n",
      "  (1, 3144)\t0.9757077\n",
      "  (1, 14975)\t0.9787143\n",
      "  (1, 16505)\t0.97459\n",
      "  (1, 17928)\t0.9862346\n",
      "  (2, 35)\t0.97747767\n",
      "  (2, 47)\t0.9815423\n",
      "  (2, 59)\t0.9803269\n",
      "  (2, 72)\t0.9879474\n",
      "  (2, 144)\t0.9740559\n",
      "  :\t:\n",
      "  (16323, 182)\t0.9782261\n",
      "  (16323, 3144)\t0.9757077\n",
      "  (16323, 14975)\t0.9787143\n",
      "  (16323, 16505)\t0.97459\n",
      "  (16323, 17928)\t0.9862346\n",
      "  (16324, 35)\t0.97747767\n",
      "  (16324, 47)\t0.9815423\n",
      "  (16324, 59)\t0.9803269\n",
      "  (16324, 72)\t0.9879474\n",
      "  (16324, 144)\t0.9740559\n",
      "  (16324, 182)\t0.9782261\n",
      "  (16324, 3144)\t0.9757077\n",
      "  (16324, 14975)\t0.9787143\n",
      "  (16324, 16505)\t0.97459\n",
      "  (16324, 17928)\t0.9862346\n",
      "  (16325, 144)\t0.9740559\n",
      "  (16325, 182)\t0.9782261\n",
      "  (16325, 334)\t0.972969\n",
      "  (16325, 756)\t0.9732626\n",
      "  (16325, 2116)\t0.97267646\n",
      "  (16325, 3144)\t0.9757077\n",
      "  (16325, 10276)\t0.9727779\n",
      "  (16325, 14975)\t0.9787143\n",
      "  (16325, 16505)\t0.97459\n",
      "  (16325, 17928)\t0.9862346\n",
      "0.00660859691815262\n"
     ]
    }
   ],
   "source": [
    "predictions = rbm.predict(train)\n",
    "print(compute_recall(true, predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}