{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyter==1.0.0 in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.0.0)\r\n",
      "Requirement already satisfied: numpy==1.21.2 in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (1.21.2)\r\n",
      "Requirement already satisfied: matplotlib==3.4.3 in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (3.4.3)\r\n",
      "Requirement already satisfied: pandas==1.3.3 in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (1.3.3)\r\n",
      "Requirement already satisfied: scikit-learn==1.0 in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (1.0)\r\n",
      "Requirement already satisfied: tqdm==4.62.3 in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (4.62.3)\r\n",
      "Requirement already satisfied: qtconsole in ./venv/lib/python3.9/site-packages (from jupyter==1.0.0->-r requirements.txt (line 1)) (5.1.1)\r\n",
      "Requirement already satisfied: ipykernel in ./venv/lib/python3.9/site-packages (from jupyter==1.0.0->-r requirements.txt (line 1)) (6.4.1)\r\n",
      "Requirement already satisfied: jupyter-console in ./venv/lib/python3.9/site-packages (from jupyter==1.0.0->-r requirements.txt (line 1)) (6.4.0)\r\n",
      "Requirement already satisfied: nbconvert in ./venv/lib/python3.9/site-packages (from jupyter==1.0.0->-r requirements.txt (line 1)) (6.2.0)\r\n",
      "Requirement already satisfied: notebook in ./venv/lib/python3.9/site-packages (from jupyter==1.0.0->-r requirements.txt (line 1)) (6.4.4)\r\n",
      "Requirement already satisfied: ipywidgets in ./venv/lib/python3.9/site-packages (from jupyter==1.0.0->-r requirements.txt (line 1)) (7.6.5)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/jules/.local/lib/python3.9/site-packages (from matplotlib==3.4.3->-r requirements.txt (line 3)) (1.3.1)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/jules/.local/lib/python3.9/site-packages (from matplotlib==3.4.3->-r requirements.txt (line 3)) (2.4.7)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jules/.local/lib/python3.9/site-packages (from matplotlib==3.4.3->-r requirements.txt (line 3)) (0.10.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/lib/python3/dist-packages (from matplotlib==3.4.3->-r requirements.txt (line 3)) (2.7.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/jules/.local/lib/python3.9/site-packages (from matplotlib==3.4.3->-r requirements.txt (line 3)) (8.2.0)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/lib/python3/dist-packages (from pandas==1.3.3->-r requirements.txt (line 4)) (2019.3)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/jules/.local/lib/python3.9/site-packages (from scikit-learn==1.0->-r requirements.txt (line 5)) (2.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /home/jules/.local/lib/python3.9/site-packages (from scikit-learn==1.0->-r requirements.txt (line 5)) (0.17.0)\r\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/jules/.local/lib/python3.9/site-packages (from scikit-learn==1.0->-r requirements.txt (line 5)) (1.6.3)\r\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from cycler>=0.10->matplotlib==3.4.3->-r requirements.txt (line 3)) (1.14.0)\r\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (6.1)\r\n",
      "Requirement already satisfied: jupyter-client<8.0 in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (7.0.6)\r\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (1.5.0)\r\n",
      "Requirement already satisfied: ipython<8.0,>=7.23.1 in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (7.28.0)\r\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (0.1.3)\r\n",
      "Requirement already satisfied: traitlets<6.0,>=4.1.0 in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (5.1.0)\r\n",
      "Requirement already satisfied: ipython-genutils in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (0.2.0)\r\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in ./venv/lib/python3.9/site-packages (from ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (1.0.2)\r\n",
      "Requirement already satisfied: nbformat>=4.2.0 in ./venv/lib/python3.9/site-packages (from ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (5.1.3)\r\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in ./venv/lib/python3.9/site-packages (from ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (3.5.1)\r\n",
      "Requirement already satisfied: pygments in ./venv/lib/python3.9/site-packages (from jupyter-console->jupyter==1.0.0->-r requirements.txt (line 1)) (2.10.0)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in ./venv/lib/python3.9/site-packages (from jupyter-console->jupyter==1.0.0->-r requirements.txt (line 1)) (3.0.20)\r\n",
      "Requirement already satisfied: jinja2>=2.4 in /usr/lib/python3/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (2.10.1)\r\n",
      "Requirement already satisfied: bleach in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (4.1.0)\r\n",
      "Requirement already satisfied: defusedxml in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.7.1)\r\n",
      "Requirement already satisfied: jupyterlab-pygments in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.1.2)\r\n",
      "Requirement already satisfied: testpath in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.5.0)\r\n",
      "Requirement already satisfied: jupyter-core in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (4.8.1)\r\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.5.4)\r\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/lib/python3/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.3)\r\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (1.5.0)\r\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.8.4)\r\n",
      "Requirement already satisfied: pyzmq>=17 in ./venv/lib/python3.9/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (22.3.0)\r\n",
      "Requirement already satisfied: terminado>=0.8.3 in ./venv/lib/python3.9/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (0.12.1)\r\n",
      "Requirement already satisfied: prometheus-client in ./venv/lib/python3.9/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (0.11.0)\r\n",
      "Requirement already satisfied: argon2-cffi in ./venv/lib/python3.9/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (21.1.0)\r\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in ./venv/lib/python3.9/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (1.8.0)\r\n",
      "Requirement already satisfied: qtpy in ./venv/lib/python3.9/site-packages (from qtconsole->jupyter==1.0.0->-r requirements.txt (line 1)) (1.11.2)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/lib/python3/dist-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (4.6.0)\r\n",
      "Requirement already satisfied: backcall in ./venv/lib/python3.9/site-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (0.2.0)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /home/jules/.local/lib/python3.9/site-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (0.17.2)\r\n",
      "Requirement already satisfied: setuptools>=18.5 in ./venv/lib/python3.9/site-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (58.1.0)\r\n",
      "Requirement already satisfied: pickleshare in ./venv/lib/python3.9/site-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (0.7.5)\r\n",
      "Requirement already satisfied: decorator in ./venv/lib/python3.9/site-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (5.1.0)\r\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in ./venv/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (1.5.1)\r\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in ./venv/lib/python3.9/site-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (4.1.0)\r\n",
      "Requirement already satisfied: wcwidth in ./venv/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter==1.0.0->-r requirements.txt (line 1)) (0.2.5)\r\n",
      "Requirement already satisfied: ptyprocess in ./venv/lib/python3.9/site-packages (from terminado>=0.8.3->notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (0.7.0)\r\n",
      "Requirement already satisfied: cffi>=1.0.0 in ./venv/lib/python3.9/site-packages (from argon2-cffi->notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (1.14.6)\r\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.9/site-packages (from bleach->nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (21.0)\r\n",
      "Requirement already satisfied: webencodings in ./venv/lib/python3.9/site-packages (from bleach->nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.5.1)\r\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.9/site-packages (from cffi>=1.0.0->argon2-cffi->notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (2.20)\r\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /home/jules/.local/lib/python3.9/site-packages (from jedi>=0.16->ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (0.7.1)\r\n",
      "Requirement already satisfied: attrs>=17.4.0 in ./venv/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (21.2.0)\r\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in ./venv/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (0.18.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import Counter\n",
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display  # removes unnecessary error reports in PyCharm\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "tqdm.pandas()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def parse_json(filename: str, read_max: int = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads the file line by line, parsing each line as json.\n",
    "    \"\"\"\n",
    "    file = gzip.open(filename, \"r\")\n",
    "    data = []\n",
    "    for index, line in enumerate(tqdm(file)):\n",
    "        if index == read_max:\n",
    "            break\n",
    "        line = line.decode()\n",
    "        line = line.replace(\"true\", \"True\")\n",
    "        line = line.replace(\"false\", \"False\")\n",
    "        data.append(eval(line))\n",
    "    print(f\"Read {len(data)} rows.\")\n",
    "    return pd.DataFrame.from_dict(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset\n",
    "\n",
    "The dataset consists of three separate files:\n",
    "\n",
    "- The books; we will only need this data to make sense of the recommendations. Using this data to make recommendations\n",
    "is (at least for now) not required for the project. It would require analysis and comparisons of the books, which is not\n",
    "a part of the base algorithm. However, being able to show which books are being recommended, rather than just showing an\n",
    "ID, is quite valuable in itself.\n",
    "\n",
    "- The reviews; this file contains all the reviews and associated ratings that the users have given. This is essentially\n",
    "the explicit feedback that we can use to generate recommendations.\n",
    "\n",
    "- The interactions; this file contains all the interactions between users and books. It contains explicit and implicit\n",
    "feedback, both of which we can use to generate recommendations. We will probably only use the implicit data if we do use\n",
    "the data in this file.\n",
    "\n",
    "We have the option of using either explicit (i.e. ratings) or implicit (i.e. interactions) data. We will explore both\n",
    "options.\n",
    "\n",
    "The following cells load the data from the files and convert them into the appropriate types. This includes parsing\n",
    "datetime strings, converting integers to numpy types, etc."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goodreads_books_comics_graphic.json.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "89411it [00:38, 2308.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 89411 rows.\n"
     ]
    },
    {
     "data": {
      "text/plain": "         isbn text_reviews_count                            series  \\\n0                              1                                []   \n1  2205073346                  2                                []   \n2                              5  [246830, 362583, 362581, 623032]   \n3                              1                                []   \n4  0930289765                  6                 [266759, 1096220]   \n\n  country_code language_code  \\\n0           US                 \n1           US           fre   \n2           US           eng   \n3           US           eng   \n4           US         en-US   \n\n                                     popular_shelves        asin is_ebook  \\\n0  [{'count': '228', 'name': 'to-read'}, {'count'...  B00NLXQ534     True   \n1  [{'count': '2', 'name': 'bd'}, {'count': '2', ...                False   \n2  [{'count': '493', 'name': 'to-read'}, {'count'...                False   \n3  [{'count': '222', 'name': 'to-read'}, {'count'...  B06XKGGSB7     True   \n4  [{'count': '20', 'name': 'to-read'}, {'count':...                False   \n\n  average_rating kindle_asin  ... publication_month edition_information  \\\n0           4.12              ...                                         \n1           3.94              ...                 1                       \n2           4.28              ...                                         \n3           4.05  B06XKGGSB7  ...                                         \n4           4.06              ...                11                       \n\n  publication_year                                                url  \\\n0                   https://www.goodreads.com/book/show/25742454-t...   \n1             2016  https://www.goodreads.com/book/show/30128855-c...   \n2             2012  https://www.goodreads.com/book/show/13571772-c...   \n3                   https://www.goodreads.com/book/show/35452242-b...   \n4             1997  https://www.goodreads.com/book/show/707611.Sup...   \n\n                                           image_url   book_id ratings_count  \\\n0  https://s.gr-assets.com/assets/nophoto/book/11...  25742454             1   \n1  https://images.gr-assets.com/books/1462644346m...  30128855            16   \n2  https://images.gr-assets.com/books/1333287305m...  13571772            51   \n3  https://s.gr-assets.com/assets/nophoto/book/11...  35452242             6   \n4  https://images.gr-assets.com/books/1307838888m...    707611            51   \n\n    work_id                                              title  \\\n0  42749946                              The Switchblade Mamma   \n1  50558228                                            Cruelle   \n2    102217  Captain America: Winter Soldier (The Ultimate ...   \n3  54276229  Bounty Hunter 4/3: My Life in Combat from Mari...   \n4    693886                          Superman Archives, Vol. 2   \n\n                                title_without_series  \n0                              The Switchblade Mamma  \n1                                            Cruelle  \n2  Captain America: Winter Soldier (The Ultimate ...  \n3  Bounty Hunter 4/3: My Life in Combat from Mari...  \n4                          Superman Archives, Vol. 2  \n\n[5 rows x 29 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>isbn</th>\n      <th>text_reviews_count</th>\n      <th>series</th>\n      <th>country_code</th>\n      <th>language_code</th>\n      <th>popular_shelves</th>\n      <th>asin</th>\n      <th>is_ebook</th>\n      <th>average_rating</th>\n      <th>kindle_asin</th>\n      <th>...</th>\n      <th>publication_month</th>\n      <th>edition_information</th>\n      <th>publication_year</th>\n      <th>url</th>\n      <th>image_url</th>\n      <th>book_id</th>\n      <th>ratings_count</th>\n      <th>work_id</th>\n      <th>title</th>\n      <th>title_without_series</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>1</td>\n      <td>[]</td>\n      <td>US</td>\n      <td></td>\n      <td>[{'count': '228', 'name': 'to-read'}, {'count'...</td>\n      <td>B00NLXQ534</td>\n      <td>True</td>\n      <td>4.12</td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>https://www.goodreads.com/book/show/25742454-t...</td>\n      <td>https://s.gr-assets.com/assets/nophoto/book/11...</td>\n      <td>25742454</td>\n      <td>1</td>\n      <td>42749946</td>\n      <td>The Switchblade Mamma</td>\n      <td>The Switchblade Mamma</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2205073346</td>\n      <td>2</td>\n      <td>[]</td>\n      <td>US</td>\n      <td>fre</td>\n      <td>[{'count': '2', 'name': 'bd'}, {'count': '2', ...</td>\n      <td></td>\n      <td>False</td>\n      <td>3.94</td>\n      <td></td>\n      <td>...</td>\n      <td>1</td>\n      <td></td>\n      <td>2016</td>\n      <td>https://www.goodreads.com/book/show/30128855-c...</td>\n      <td>https://images.gr-assets.com/books/1462644346m...</td>\n      <td>30128855</td>\n      <td>16</td>\n      <td>50558228</td>\n      <td>Cruelle</td>\n      <td>Cruelle</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>5</td>\n      <td>[246830, 362583, 362581, 623032]</td>\n      <td>US</td>\n      <td>eng</td>\n      <td>[{'count': '493', 'name': 'to-read'}, {'count'...</td>\n      <td></td>\n      <td>False</td>\n      <td>4.28</td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td>2012</td>\n      <td>https://www.goodreads.com/book/show/13571772-c...</td>\n      <td>https://images.gr-assets.com/books/1333287305m...</td>\n      <td>13571772</td>\n      <td>51</td>\n      <td>102217</td>\n      <td>Captain America: Winter Soldier (The Ultimate ...</td>\n      <td>Captain America: Winter Soldier (The Ultimate ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>1</td>\n      <td>[]</td>\n      <td>US</td>\n      <td>eng</td>\n      <td>[{'count': '222', 'name': 'to-read'}, {'count'...</td>\n      <td>B06XKGGSB7</td>\n      <td>True</td>\n      <td>4.05</td>\n      <td>B06XKGGSB7</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>https://www.goodreads.com/book/show/35452242-b...</td>\n      <td>https://s.gr-assets.com/assets/nophoto/book/11...</td>\n      <td>35452242</td>\n      <td>6</td>\n      <td>54276229</td>\n      <td>Bounty Hunter 4/3: My Life in Combat from Mari...</td>\n      <td>Bounty Hunter 4/3: My Life in Combat from Mari...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0930289765</td>\n      <td>6</td>\n      <td>[266759, 1096220]</td>\n      <td>US</td>\n      <td>en-US</td>\n      <td>[{'count': '20', 'name': 'to-read'}, {'count':...</td>\n      <td></td>\n      <td>False</td>\n      <td>4.06</td>\n      <td></td>\n      <td>...</td>\n      <td>11</td>\n      <td></td>\n      <td>1997</td>\n      <td>https://www.goodreads.com/book/show/707611.Sup...</td>\n      <td>https://images.gr-assets.com/books/1307838888m...</td>\n      <td>707611</td>\n      <td>51</td>\n      <td>693886</td>\n      <td>Superman Archives, Vol. 2</td>\n      <td>Superman Archives, Vol. 2</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 29 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goodreads_interactions_comics_graphic.json.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500000it [00:14, 33417.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 500000 rows.\n"
     ]
    },
    {
     "data": {
      "text/plain": "                            user_id   book_id  \\\n0  8842281e1d1347389f2ab93d60773d4d    836610   \n1  8842281e1d1347389f2ab93d60773d4d   7648967   \n2  8842281e1d1347389f2ab93d60773d4d  15704307   \n3  8842281e1d1347389f2ab93d60773d4d   6902644   \n4  8842281e1d1347389f2ab93d60773d4d   9844623   \n\n                          review_id  is_read  rating review_text_incomplete  \\\n0  6b4db26aafeaf0da77c7de6214331e1e    False       0                          \n1  99b27059f711c37de8f90ee8e4dc0d1b    False       0                          \n2  cb944d94854df5afd22210bb0aa0c903    False       0                          \n3  2711bac2a8cc600dae1590a6ca0edb34    False       0                          \n4  b72979076d1cded25dded922195e5b1c    False       0                          \n\n                       date_added                    date_updated read_at  \\\n0  Mon Aug 21 12:11:00 -0700 2017  Mon Aug 21 12:11:00 -0700 2017           \n1  Fri Feb 24 08:59:44 -0800 2017  Fri Feb 24 08:59:44 -0800 2017           \n2  Wed May 20 21:28:56 -0700 2015  Wed May 20 21:28:57 -0700 2015           \n3  Sun Jun 01 17:25:23 -0700 2014  Sun Jun 01 17:25:23 -0700 2014           \n4  Sun Sep 02 08:45:08 -0700 2012  Sun Sep 02 08:45:08 -0700 2012           \n\n  started_at  \n0             \n1             \n2             \n3             \n4             ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>book_id</th>\n      <th>review_id</th>\n      <th>is_read</th>\n      <th>rating</th>\n      <th>review_text_incomplete</th>\n      <th>date_added</th>\n      <th>date_updated</th>\n      <th>read_at</th>\n      <th>started_at</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8842281e1d1347389f2ab93d60773d4d</td>\n      <td>836610</td>\n      <td>6b4db26aafeaf0da77c7de6214331e1e</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td>Mon Aug 21 12:11:00 -0700 2017</td>\n      <td>Mon Aug 21 12:11:00 -0700 2017</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8842281e1d1347389f2ab93d60773d4d</td>\n      <td>7648967</td>\n      <td>99b27059f711c37de8f90ee8e4dc0d1b</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td>Fri Feb 24 08:59:44 -0800 2017</td>\n      <td>Fri Feb 24 08:59:44 -0800 2017</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8842281e1d1347389f2ab93d60773d4d</td>\n      <td>15704307</td>\n      <td>cb944d94854df5afd22210bb0aa0c903</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td>Wed May 20 21:28:56 -0700 2015</td>\n      <td>Wed May 20 21:28:57 -0700 2015</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8842281e1d1347389f2ab93d60773d4d</td>\n      <td>6902644</td>\n      <td>2711bac2a8cc600dae1590a6ca0edb34</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td>Sun Jun 01 17:25:23 -0700 2014</td>\n      <td>Sun Jun 01 17:25:23 -0700 2014</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8842281e1d1347389f2ab93d60773d4d</td>\n      <td>9844623</td>\n      <td>b72979076d1cded25dded922195e5b1c</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td>Sun Sep 02 08:45:08 -0700 2012</td>\n      <td>Sun Sep 02 08:45:08 -0700 2012</td>\n      <td></td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goodreads_reviews_comics_graphic.json.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500000it [00:19, 25743.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 500000 rows.\n"
     ]
    },
    {
     "data": {
      "text/plain": "                            user_id   book_id  \\\n0  dc3763cdb9b2cae805882878eebb6a32  18471619   \n1  bafc2d50014200cda7cb2b6acd60cd73   6315584   \n2  bafc2d50014200cda7cb2b6acd60cd73  29847729   \n3  bafc2d50014200cda7cb2b6acd60cd73  18454118   \n4  bafc2d50014200cda7cb2b6acd60cd73   2239435   \n\n                          review_id  rating  \\\n0  66b2ba840f9bd36d6d27f46136fe4772       3   \n1  72f1229aba5a88f9e72f0dcdc007dd22       4   \n2  a75309355f8662caaa5e2c92ab693d3f       4   \n3  c3cc5a3e1d6b6c9cf1c044f306c8e752       5   \n4  cc444be37ab0a42bfb4dd818cb5edd10       4   \n\n                                         review_text  \\\n0  Sherlock Holmes and the Vampires of London \\n ...   \n1  I've never really liked Spider-Man. I am, howe...   \n2  A very quick introduction, this is coming out ...   \n3  I've been waiting so long for this. I first st...   \n4  The only thing more entertaining than this boo...   \n\n                       date_added                    date_updated  \\\n0  Thu Dec 05 10:44:25 -0800 2013  Thu Dec 05 10:45:15 -0800 2013   \n1  Wed Aug 10 06:06:48 -0700 2016  Fri Aug 12 08:49:54 -0700 2016   \n2  Thu Apr 21 07:44:00 -0700 2016  Thu Apr 21 07:59:28 -0700 2016   \n3  Mon Mar 03 17:45:56 -0800 2014  Mon Mar 03 17:54:11 -0800 2014   \n4  Wed Apr 03 12:37:48 -0700 2013  Wed Apr 03 13:03:36 -0700 2013   \n\n                          read_at                      started_at  n_votes  \\\n0  Tue Nov 05 00:00:00 -0800 2013                                        0   \n1  Fri Aug 12 08:49:54 -0700 2016  Wed Aug 10 00:00:00 -0700 2016        0   \n2  Thu Apr 21 07:59:28 -0700 2016  Thu Apr 21 00:00:00 -0700 2016        0   \n3  Sat Mar 01 00:00:00 -0800 2014  Sat Mar 01 00:00:00 -0800 2014        1   \n4  Wed Apr 03 13:03:36 -0700 2013                                        0   \n\n   n_comments  \n0           0  \n1           0  \n2           0  \n3           0  \n4           0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>book_id</th>\n      <th>review_id</th>\n      <th>rating</th>\n      <th>review_text</th>\n      <th>date_added</th>\n      <th>date_updated</th>\n      <th>read_at</th>\n      <th>started_at</th>\n      <th>n_votes</th>\n      <th>n_comments</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dc3763cdb9b2cae805882878eebb6a32</td>\n      <td>18471619</td>\n      <td>66b2ba840f9bd36d6d27f46136fe4772</td>\n      <td>3</td>\n      <td>Sherlock Holmes and the Vampires of London \\n ...</td>\n      <td>Thu Dec 05 10:44:25 -0800 2013</td>\n      <td>Thu Dec 05 10:45:15 -0800 2013</td>\n      <td>Tue Nov 05 00:00:00 -0800 2013</td>\n      <td></td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bafc2d50014200cda7cb2b6acd60cd73</td>\n      <td>6315584</td>\n      <td>72f1229aba5a88f9e72f0dcdc007dd22</td>\n      <td>4</td>\n      <td>I've never really liked Spider-Man. I am, howe...</td>\n      <td>Wed Aug 10 06:06:48 -0700 2016</td>\n      <td>Fri Aug 12 08:49:54 -0700 2016</td>\n      <td>Fri Aug 12 08:49:54 -0700 2016</td>\n      <td>Wed Aug 10 00:00:00 -0700 2016</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bafc2d50014200cda7cb2b6acd60cd73</td>\n      <td>29847729</td>\n      <td>a75309355f8662caaa5e2c92ab693d3f</td>\n      <td>4</td>\n      <td>A very quick introduction, this is coming out ...</td>\n      <td>Thu Apr 21 07:44:00 -0700 2016</td>\n      <td>Thu Apr 21 07:59:28 -0700 2016</td>\n      <td>Thu Apr 21 07:59:28 -0700 2016</td>\n      <td>Thu Apr 21 00:00:00 -0700 2016</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>bafc2d50014200cda7cb2b6acd60cd73</td>\n      <td>18454118</td>\n      <td>c3cc5a3e1d6b6c9cf1c044f306c8e752</td>\n      <td>5</td>\n      <td>I've been waiting so long for this. I first st...</td>\n      <td>Mon Mar 03 17:45:56 -0800 2014</td>\n      <td>Mon Mar 03 17:54:11 -0800 2014</td>\n      <td>Sat Mar 01 00:00:00 -0800 2014</td>\n      <td>Sat Mar 01 00:00:00 -0800 2014</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bafc2d50014200cda7cb2b6acd60cd73</td>\n      <td>2239435</td>\n      <td>cc444be37ab0a42bfb4dd818cb5edd10</td>\n      <td>4</td>\n      <td>The only thing more entertaining than this boo...</td>\n      <td>Wed Apr 03 12:37:48 -0700 2013</td>\n      <td>Wed Apr 03 13:03:36 -0700 2013</td>\n      <td>Wed Apr 03 13:03:36 -0700 2013</td>\n      <td></td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = \"data/\"\n",
    "books = \"goodreads_books_comics_graphic.json.gz\"\n",
    "interactions = \"goodreads_interactions_comics_graphic.json.gz\"\n",
    "reviews = \"goodreads_reviews_comics_graphic.json.gz\"\n",
    "datasets = {books: None, interactions: None, reviews: None}\n",
    "\n",
    "# The maximum number of lines to read from each file\n",
    "n = 500000\n",
    "\n",
    "# The filename of the matrix data file (i.e. interactions or reviews) we're currently using\n",
    "datafile = reviews\n",
    "\n",
    "for filename in datasets.keys():\n",
    "    print(filename)\n",
    "    datasets[filename] = parse_json(data_path + filename, n)\n",
    "    display(datasets[filename].head(5))\n",
    "\n",
    "books_df = datasets[books][[\"book_id\", \"title\"]].copy()\n",
    "interactions_df = datasets[datafile][[\"user_id\", \"book_id\", \"rating\", \"date_updated\"]].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "format_str = \"%a %b %d %H:%M:%S %z %Y\"\n",
    "interactions_df[\"date_updated\"] = pd.to_datetime(interactions_df[\"date_updated\"], format=format_str)\n",
    "\n",
    "books_df[\"book_id\"] = books_df[\"book_id\"].astype(\"int64\")\n",
    "interactions_df[\"book_id\"] = interactions_df[\"book_id\"].astype(\"int64\")\n",
    "\n",
    "interactions_df = interactions_df.sort_values(by=[\"user_id\", \"date_updated\"], ascending=[True, True])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [00:00<00:00, 1228083.06it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ratings_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_39846/218516320.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0minteractions_df\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"user_id_int\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minteractions_df\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"user_id\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprogress_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmap_to_consecutive_ids\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m \u001B[0mratings_df\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"user_id_int\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mratings_df\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"user_id\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprogress_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0muser_id\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mids\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0muser_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m \u001B[0mids\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0mbooks_df\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"book_id_int\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbooks_df\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"book_id\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprogress_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmap_to_consecutive_ids\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ratings_df' is not defined"
     ]
    }
   ],
   "source": [
    "def apply_consecutive_mapping(dataframe: pd.DataFrame, column: str, new_column: str, *additional: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Generates a consecutive ID column for the values of an existing column. Also adds this column to additional data\n",
    "    frames with the exact same mapping of old ID to new (consecutive) ID.\n",
    "    \"\"\"\n",
    "    ids = {}\n",
    "\n",
    "    def map_to_consecutive_ids(uuid: Union[int, np.int64]) -> int:\n",
    "        \"\"\"\n",
    "        To be used with `pd.Dataframe.apply()` or `pd.Dataframe.progress_apply()`; returns a unique ID per distinct value.\n",
    "        (Using the function attribute `map_to_consecutive_ids.ids` to avoid namespace pollution.\n",
    "        \"\"\"\n",
    "        if uuid not in ids:\n",
    "            ids[uuid] = len(ids)\n",
    "        return ids[uuid]\n",
    "\n",
    "    dataframe[new_column] = dataframe[column].progress_apply(map_to_consecutive_ids)\n",
    "    for frame in additional:\n",
    "        frame[new_column] = frame[column].progress_apply(lambda old_id: ids.get(old_id, -1))\n",
    "\n",
    "\n",
    "apply_consecutive_mapping(interactions_df, \"user_id\", \"user_id_int\")\n",
    "apply_consecutive_mapping(books_df, \"book_id\", \"book_id_int\", interactions_df)\n",
    "\n",
    "display(books_df.head(10))\n",
    "display(interactions_df.head(10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def preprocess(df: pd.DataFrame, min_support: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Removes reconsumption items, items that have less than `min_support` interactions, and users that have less than\n",
    "    `min_support` interactions.\n",
    "    \"\"\"\n",
    "    print(df.shape[0], \"initial rows\")\n",
    "    # Drop reconsumption items\n",
    "    df = df.drop_duplicates(subset=[\"user_id\", \"item_id\"])\n",
    "    print(df.shape[0], \"rows after removing reconsumption items\")\n",
    "    # Compute user and item counts\n",
    "    g1 = df.groupby(\"item_id\", as_index=False)[\"user_id\"].size()\n",
    "    g1 = g1.rename({\"size\": \"users_per_item\"}, axis=\"columns\")\n",
    "    g2 = df.groupby(\"user_id\", as_index=False)[\"item_id\"].size()\n",
    "    g2 = g2.rename({\"size\": \"items_per_user\"}, axis=\"columns\")\n",
    "    df = pd.merge(df, g1, how=\"left\", on=[\"item_id\"])\n",
    "    df = pd.merge(df, g2, how=\"left\", on=[\"user_id\"])\n",
    "    # Drop items and users with less than `min_support` interactions\n",
    "    df = df[df[\"users_per_item\"] >= min_support]\n",
    "    print(df.shape[0], \"rows after removing infrequent items\")\n",
    "    df = df[df[\"items_per_user\"] >= min_support]\n",
    "    print(df.shape[0], \"rows after removing infrequent users\")\n",
    "    df = df[[\"user_id\", \"item_id\", \"datetime\", \"rating\"]].copy()\n",
    "    return df\n",
    "\n",
    "\n",
    "interactions_processed = interactions_df[[\"user_id_int\", \"book_id_int\", \"date_updated\", \"rating\"]].copy()\n",
    "interactions_processed = interactions_processed.rename(\n",
    "    columns={\"user_id_int\": \"user_id\", \"book_id_int\": \"item_id\", \"date_updated\": \"datetime\"})\n",
    "display(interactions_processed.head(5))\n",
    "print(f\"Number of unique users:\", interactions_processed[\"user_id\"].nunique())\n",
    "print(f\"Number of unique items:\", interactions_processed[\"item_id\"].nunique())\n",
    "interactions_processed = preprocess(interactions_processed)\n",
    "print(f\"Number of unique users:\", interactions_processed[\"user_id\"].nunique())\n",
    "print(f\"Number of unique items:\", interactions_processed[\"item_id\"].nunique())\n",
    "display(interactions_processed.head(5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def split(items: list[int], percentage_train: float) -> pd.Series:\n",
    "    nr_train_items = int(len(items) * percentage_train)\n",
    "    return pd.Series((items[: nr_train_items], items[nr_train_items:]))\n",
    "\n",
    "\n",
    "sessions_df = interactions_processed.groupby(by=\"user_id\", as_index=False)[[\"item_id\", \"datetime\", \"rating\"]].agg(list)\n",
    "display(sessions_df.head(5))\n",
    "\n",
    "percentage_train = 0.8\n",
    "sessions_df[[\"history\", \"future\"]] = sessions_df[\"item_id\"].progress_apply(split, args=(percentage_train,))\n",
    "display(sessions_df.head(5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_sparse_matrix(dataframe: pd.DataFrame, column: str = \"history\",\n",
    "                         shape: tuple[int, int] = None) -> sparse.csr_matrix:\n",
    "    \"\"\"\n",
    "    Creates a sparse matrix from the data in `dataframe`.\n",
    "    \"\"\"\n",
    "    # Flatten the dataframe\n",
    "    user_ids = []\n",
    "    item_ids = []\n",
    "    for index, row in dataframe.iterrows():\n",
    "        user_ids.extend([row[\"user_id\"]] * len(row[column]))\n",
    "        item_ids.extend(row[column])\n",
    "    # Create the CSR matrix\n",
    "    values = np.ones(len(user_ids))\n",
    "    return sparse.csr_matrix((values, (user_ids, item_ids)), shape=shape, dtype=np.int32)\n",
    "\n",
    "\n",
    "shape = (interactions_processed[\"user_id\"].max() + 1, interactions_processed[\"item_id\"].max() + 1)\n",
    "train = create_sparse_matrix(sessions_df, \"history\", shape)\n",
    "true = create_sparse_matrix(sessions_df, \"future\", shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class PopularityRecommender:\n",
    "    def __init__(self, k: int = 10) -> None:\n",
    "        self.k = k\n",
    "        self.scores = []\n",
    "\n",
    "    def fit(self, data: sparse.csr_matrix) -> None:\n",
    "        items = list(data.nonzero()[1])\n",
    "        scores = Counter(items).most_common(self.k)\n",
    "        self.scores = [(item, score / scores[0][1]) for item, score in scores]\n",
    "\n",
    "    def predict(self, data: sparse.csr_matrix) -> sparse.csr_matrix:\n",
    "        items, values = zip(*self.scores)\n",
    "        users = set(data.nonzero()[0])\n",
    "\n",
    "        matrix_data = ([], ([], []))\n",
    "        for user in users:\n",
    "            matrix_data[0].extend(values)\n",
    "            matrix_data[1][0].extend([user] * self.k)\n",
    "            matrix_data[1][1].extend(items)\n",
    "        return sparse.csr_matrix(matrix_data, shape=data.shape)\n",
    "\n",
    "\n",
    "k = 20\n",
    "recommender = PopularityRecommender(k)\n",
    "recommender.fit(train)\n",
    "predicted = recommender.predict(train)\n",
    "print(predicted)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def sparse_invert_nonzero(a: sparse.csr_matrix) -> sparse.csr_matrix:\n",
    "    inverse = a.copy()\n",
    "    inverse.data = 1 / inverse.data\n",
    "    return inverse\n",
    "\n",
    "\n",
    "def sparse_divide_nonzero(a: sparse.csr_matrix, b: sparse.csr_matrix) -> sparse.csr_matrix:\n",
    "    return a.multiply(sparse_invert_nonzero(b))\n",
    "\n",
    "\n",
    "def compute_recall(true: sparse.csr_matrix, predicted: sparse.csr_matrix) -> float:\n",
    "    scores = sparse.lil_matrix(predicted.shape)\n",
    "    scores[predicted.multiply(true).astype(bool)] = 1\n",
    "    scores = sparse_divide_nonzero(scores.tocsr(), sparse.csr_matrix(true.sum(axis=1))).sum(axis=1)\n",
    "    return scores.mean()\n",
    "\n",
    "\n",
    "recall = compute_recall(true, predicted)\n",
    "print(f\"Recall @ {k}: {recall:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}