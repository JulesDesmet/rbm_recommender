{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyter==1.0.0 in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.0.0)\r\n",
      "Requirement already satisfied: numpy==1.21.3 in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (1.21.3)\r\n",
      "Requirement already satisfied: matplotlib==3.4.3 in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (3.4.3)\r\n",
      "Requirement already satisfied: pandas==1.3.4 in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (1.3.4)\r\n",
      "Requirement already satisfied: scikit-learn==1.0.1 in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (1.0.1)\r\n",
      "Requirement already satisfied: torch==1.10.0 in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (1.10.0)\r\n",
      "Requirement already satisfied: tqdm==4.62.3 in ./venv/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (4.62.3)\r\n",
      "Requirement already satisfied: notebook in ./venv/lib/python3.9/site-packages (from jupyter==1.0.0->-r requirements.txt (line 1)) (6.4.4)\r\n",
      "Requirement already satisfied: ipykernel in ./venv/lib/python3.9/site-packages (from jupyter==1.0.0->-r requirements.txt (line 1)) (6.4.1)\r\n",
      "Requirement already satisfied: jupyter-console in ./venv/lib/python3.9/site-packages (from jupyter==1.0.0->-r requirements.txt (line 1)) (6.4.0)\r\n",
      "Requirement already satisfied: ipywidgets in ./venv/lib/python3.9/site-packages (from jupyter==1.0.0->-r requirements.txt (line 1)) (7.6.5)\r\n",
      "Requirement already satisfied: qtconsole in ./venv/lib/python3.9/site-packages (from jupyter==1.0.0->-r requirements.txt (line 1)) (5.1.1)\r\n",
      "Requirement already satisfied: nbconvert in ./venv/lib/python3.9/site-packages (from jupyter==1.0.0->-r requirements.txt (line 1)) (6.2.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/jules/.local/lib/python3.9/site-packages (from matplotlib==3.4.3->-r requirements.txt (line 3)) (2.4.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/lib/python3/dist-packages (from matplotlib==3.4.3->-r requirements.txt (line 3)) (2.7.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/jules/.local/lib/python3.9/site-packages (from matplotlib==3.4.3->-r requirements.txt (line 3)) (8.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jules/.local/lib/python3.9/site-packages (from matplotlib==3.4.3->-r requirements.txt (line 3)) (0.10.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/jules/.local/lib/python3.9/site-packages (from matplotlib==3.4.3->-r requirements.txt (line 3)) (1.3.1)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/lib/python3/dist-packages (from pandas==1.3.4->-r requirements.txt (line 4)) (2019.3)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/jules/.local/lib/python3.9/site-packages (from scikit-learn==1.0.1->-r requirements.txt (line 5)) (2.1.0)\r\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/jules/.local/lib/python3.9/site-packages (from scikit-learn==1.0.1->-r requirements.txt (line 5)) (1.6.3)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /home/jules/.local/lib/python3.9/site-packages (from scikit-learn==1.0.1->-r requirements.txt (line 5)) (0.17.0)\r\n",
      "Requirement already satisfied: typing-extensions in /home/jules/.local/lib/python3.9/site-packages (from torch==1.10.0->-r requirements.txt (line 6)) (3.7.4.3)\r\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from cycler>=0.10->matplotlib==3.4.3->-r requirements.txt (line 3)) (1.14.0)\r\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (0.1.3)\r\n",
      "Requirement already satisfied: ipython<8.0,>=7.23.1 in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (7.28.0)\r\n",
      "Requirement already satisfied: ipython-genutils in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (0.2.0)\r\n",
      "Requirement already satisfied: traitlets<6.0,>=4.1.0 in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (5.1.0)\r\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (1.5.0)\r\n",
      "Requirement already satisfied: jupyter-client<8.0 in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (7.0.6)\r\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in ./venv/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (6.1)\r\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in ./venv/lib/python3.9/site-packages (from ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (3.5.1)\r\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in ./venv/lib/python3.9/site-packages (from ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (1.0.2)\r\n",
      "Requirement already satisfied: nbformat>=4.2.0 in ./venv/lib/python3.9/site-packages (from ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (5.1.3)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in ./venv/lib/python3.9/site-packages (from jupyter-console->jupyter==1.0.0->-r requirements.txt (line 1)) (3.0.20)\r\n",
      "Requirement already satisfied: pygments in ./venv/lib/python3.9/site-packages (from jupyter-console->jupyter==1.0.0->-r requirements.txt (line 1)) (2.10.0)\r\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.8.4)\r\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (1.5.0)\r\n",
      "Requirement already satisfied: testpath in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.5.0)\r\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.5.4)\r\n",
      "Requirement already satisfied: jupyter-core in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (4.8.1)\r\n",
      "Requirement already satisfied: jupyterlab-pygments in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.1.2)\r\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/lib/python3/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.3)\r\n",
      "Requirement already satisfied: bleach in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (4.1.0)\r\n",
      "Requirement already satisfied: jinja2>=2.4 in /usr/lib/python3/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (2.10.1)\r\n",
      "Requirement already satisfied: defusedxml in ./venv/lib/python3.9/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.7.1)\r\n",
      "Requirement already satisfied: prometheus-client in ./venv/lib/python3.9/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (0.11.0)\r\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in ./venv/lib/python3.9/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (1.8.0)\r\n",
      "Requirement already satisfied: argon2-cffi in ./venv/lib/python3.9/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (21.1.0)\r\n",
      "Requirement already satisfied: pyzmq>=17 in ./venv/lib/python3.9/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (22.3.0)\r\n",
      "Requirement already satisfied: terminado>=0.8.3 in ./venv/lib/python3.9/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (0.12.1)\r\n",
      "Requirement already satisfied: qtpy in ./venv/lib/python3.9/site-packages (from qtconsole->jupyter==1.0.0->-r requirements.txt (line 1)) (1.11.2)\r\n",
      "Requirement already satisfied: pickleshare in ./venv/lib/python3.9/site-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (0.7.5)\r\n",
      "Requirement already satisfied: setuptools>=18.5 in ./venv/lib/python3.9/site-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (58.1.0)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/lib/python3/dist-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (4.6.0)\r\n",
      "Requirement already satisfied: decorator in ./venv/lib/python3.9/site-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (5.1.0)\r\n",
      "Requirement already satisfied: backcall in ./venv/lib/python3.9/site-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (0.2.0)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /home/jules/.local/lib/python3.9/site-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (0.17.2)\r\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in ./venv/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (1.5.1)\r\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in ./venv/lib/python3.9/site-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (4.1.0)\r\n",
      "Requirement already satisfied: wcwidth in ./venv/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter==1.0.0->-r requirements.txt (line 1)) (0.2.5)\r\n",
      "Requirement already satisfied: ptyprocess in ./venv/lib/python3.9/site-packages (from terminado>=0.8.3->notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (0.7.0)\r\n",
      "Requirement already satisfied: cffi>=1.0.0 in ./venv/lib/python3.9/site-packages (from argon2-cffi->notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (1.14.6)\r\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.9/site-packages (from bleach->nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (21.0)\r\n",
      "Requirement already satisfied: webencodings in ./venv/lib/python3.9/site-packages (from bleach->nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.5.1)\r\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.9/site-packages (from cffi>=1.0.0->argon2-cffi->notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (2.20)\r\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /home/jules/.local/lib/python3.9/site-packages (from jedi>=0.16->ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (0.7.1)\r\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in ./venv/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (0.18.0)\r\n",
      "Requirement already satisfied: attrs>=17.4.0 in ./venv/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (21.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import Counter\n",
    "from json import loads\n",
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from IPython.display import display  # removes unnecessary error reports in PyCharm\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "tqdm.pandas()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def parse_json(filename: str, read_max: int = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads the file line by line, parsing each line as json.\n",
    "    \"\"\"\n",
    "    file = gzip.open(filename, \"r\")\n",
    "    data = []\n",
    "    for index, line in enumerate(tqdm(file)):\n",
    "        if index == read_max:\n",
    "            break\n",
    "        data.append(loads(line))\n",
    "    print(f\"Read {len(data)} rows.\")\n",
    "    return pd.DataFrame.from_dict(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset\n",
    "\n",
    "The dataset consists of three separate files:\n",
    "\n",
    "- The books; we will only need this data to make sense of the recommendations. Using this data to make recommendations\n",
    "is (at least for now) not required for the project. It would require analysis and comparisons of the books, which is not\n",
    "a part of the base algorithm. However, being able to show which books are being recommended, rather than just showing an\n",
    "ID, is quite valuable in itself.\n",
    "\n",
    "- The reviews; this file contains all the reviews and associated ratings that the users have given. This is essentially\n",
    "the explicit feedback that we can use to generate recommendations.\n",
    "\n",
    "- The interactions; this file contains all the interactions between users and books. It contains explicit and implicit\n",
    "feedback, both of which we can use to generate recommendations. We will probably only use the implicit data if we do use\n",
    "the data in this file.\n",
    "\n",
    "We have the option of using either explicit (i.e. ratings) or implicit (i.e. interactions) data. Because the paper\n",
    "discusses the prediction of ratings, this is also what we will be doing.\n",
    "\n",
    "The following cells load the data from the files and convert them into the appropriate types. This includes parsing\n",
    "datetime strings, converting integers to numpy types, etc.\n",
    "\n",
    "## Important variables/settings\n",
    "\n",
    "- *n* determines the maximum number of rows read from any of the files.\n",
    "- *datafile*, which can be either `interactions` or `reviews`, determines the file from which the data matrix will be\n",
    "read.\n",
    "- *k* determines the number of predictions the recommender will make, and on how many predictions it will be evaluated,\n",
    "e.g. by using `Recall@k`.\n",
    "- *epochs* determines the number of epochs we will use to train the recommender."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goodreads_books_comics_graphic.json.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "89411it [00:05, 15358.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 89411 rows.\n"
     ]
    },
    {
     "data": {
      "text/plain": "         isbn text_reviews_count                            series  \\\n0                              1                                []   \n1  2205073346                  2                                []   \n2                              5  [246830, 362583, 362581, 623032]   \n3                              1                                []   \n4  0930289765                  6                 [266759, 1096220]   \n\n  country_code language_code  \\\n0           US                 \n1           US           fre   \n2           US           eng   \n3           US           eng   \n4           US         en-US   \n\n                                     popular_shelves        asin is_ebook  \\\n0  [{'count': '228', 'name': 'to-read'}, {'count'...  B00NLXQ534     true   \n1  [{'count': '2', 'name': 'bd'}, {'count': '2', ...                false   \n2  [{'count': '493', 'name': 'to-read'}, {'count'...                false   \n3  [{'count': '222', 'name': 'to-read'}, {'count'...  B06XKGGSB7     true   \n4  [{'count': '20', 'name': 'to-read'}, {'count':...                false   \n\n  average_rating kindle_asin  ... publication_month edition_information  \\\n0           4.12              ...                                         \n1           3.94              ...                 1                       \n2           4.28              ...                                         \n3           4.05  B06XKGGSB7  ...                                         \n4           4.06              ...                11                       \n\n  publication_year                                                url  \\\n0                   https://www.goodreads.com/book/show/25742454-t...   \n1             2016  https://www.goodreads.com/book/show/30128855-c...   \n2             2012  https://www.goodreads.com/book/show/13571772-c...   \n3                   https://www.goodreads.com/book/show/35452242-b...   \n4             1997  https://www.goodreads.com/book/show/707611.Sup...   \n\n                                           image_url   book_id ratings_count  \\\n0  https://s.gr-assets.com/assets/nophoto/book/11...  25742454             1   \n1  https://images.gr-assets.com/books/1462644346m...  30128855            16   \n2  https://images.gr-assets.com/books/1333287305m...  13571772            51   \n3  https://s.gr-assets.com/assets/nophoto/book/11...  35452242             6   \n4  https://images.gr-assets.com/books/1307838888m...    707611            51   \n\n    work_id                                              title  \\\n0  42749946                              The Switchblade Mamma   \n1  50558228                                            Cruelle   \n2    102217  Captain America: Winter Soldier (The Ultimate ...   \n3  54276229  Bounty Hunter 4/3: My Life in Combat from Mari...   \n4    693886                          Superman Archives, Vol. 2   \n\n                                title_without_series  \n0                              The Switchblade Mamma  \n1                                            Cruelle  \n2  Captain America: Winter Soldier (The Ultimate ...  \n3  Bounty Hunter 4/3: My Life in Combat from Mari...  \n4                          Superman Archives, Vol. 2  \n\n[5 rows x 29 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>isbn</th>\n      <th>text_reviews_count</th>\n      <th>series</th>\n      <th>country_code</th>\n      <th>language_code</th>\n      <th>popular_shelves</th>\n      <th>asin</th>\n      <th>is_ebook</th>\n      <th>average_rating</th>\n      <th>kindle_asin</th>\n      <th>...</th>\n      <th>publication_month</th>\n      <th>edition_information</th>\n      <th>publication_year</th>\n      <th>url</th>\n      <th>image_url</th>\n      <th>book_id</th>\n      <th>ratings_count</th>\n      <th>work_id</th>\n      <th>title</th>\n      <th>title_without_series</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>1</td>\n      <td>[]</td>\n      <td>US</td>\n      <td></td>\n      <td>[{'count': '228', 'name': 'to-read'}, {'count'...</td>\n      <td>B00NLXQ534</td>\n      <td>true</td>\n      <td>4.12</td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>https://www.goodreads.com/book/show/25742454-t...</td>\n      <td>https://s.gr-assets.com/assets/nophoto/book/11...</td>\n      <td>25742454</td>\n      <td>1</td>\n      <td>42749946</td>\n      <td>The Switchblade Mamma</td>\n      <td>The Switchblade Mamma</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2205073346</td>\n      <td>2</td>\n      <td>[]</td>\n      <td>US</td>\n      <td>fre</td>\n      <td>[{'count': '2', 'name': 'bd'}, {'count': '2', ...</td>\n      <td></td>\n      <td>false</td>\n      <td>3.94</td>\n      <td></td>\n      <td>...</td>\n      <td>1</td>\n      <td></td>\n      <td>2016</td>\n      <td>https://www.goodreads.com/book/show/30128855-c...</td>\n      <td>https://images.gr-assets.com/books/1462644346m...</td>\n      <td>30128855</td>\n      <td>16</td>\n      <td>50558228</td>\n      <td>Cruelle</td>\n      <td>Cruelle</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>5</td>\n      <td>[246830, 362583, 362581, 623032]</td>\n      <td>US</td>\n      <td>eng</td>\n      <td>[{'count': '493', 'name': 'to-read'}, {'count'...</td>\n      <td></td>\n      <td>false</td>\n      <td>4.28</td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td>2012</td>\n      <td>https://www.goodreads.com/book/show/13571772-c...</td>\n      <td>https://images.gr-assets.com/books/1333287305m...</td>\n      <td>13571772</td>\n      <td>51</td>\n      <td>102217</td>\n      <td>Captain America: Winter Soldier (The Ultimate ...</td>\n      <td>Captain America: Winter Soldier (The Ultimate ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>1</td>\n      <td>[]</td>\n      <td>US</td>\n      <td>eng</td>\n      <td>[{'count': '222', 'name': 'to-read'}, {'count'...</td>\n      <td>B06XKGGSB7</td>\n      <td>true</td>\n      <td>4.05</td>\n      <td>B06XKGGSB7</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>https://www.goodreads.com/book/show/35452242-b...</td>\n      <td>https://s.gr-assets.com/assets/nophoto/book/11...</td>\n      <td>35452242</td>\n      <td>6</td>\n      <td>54276229</td>\n      <td>Bounty Hunter 4/3: My Life in Combat from Mari...</td>\n      <td>Bounty Hunter 4/3: My Life in Combat from Mari...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0930289765</td>\n      <td>6</td>\n      <td>[266759, 1096220]</td>\n      <td>US</td>\n      <td>en-US</td>\n      <td>[{'count': '20', 'name': 'to-read'}, {'count':...</td>\n      <td></td>\n      <td>false</td>\n      <td>4.06</td>\n      <td></td>\n      <td>...</td>\n      <td>11</td>\n      <td></td>\n      <td>1997</td>\n      <td>https://www.goodreads.com/book/show/707611.Sup...</td>\n      <td>https://images.gr-assets.com/books/1307838888m...</td>\n      <td>707611</td>\n      <td>51</td>\n      <td>693886</td>\n      <td>Superman Archives, Vol. 2</td>\n      <td>Superman Archives, Vol. 2</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 29 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goodreads_interactions_comics_graphic.json.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 152962.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 100000 rows.\n"
     ]
    },
    {
     "data": {
      "text/plain": "                            user_id   book_id  \\\n0  8842281e1d1347389f2ab93d60773d4d    836610   \n1  8842281e1d1347389f2ab93d60773d4d   7648967   \n2  8842281e1d1347389f2ab93d60773d4d  15704307   \n3  8842281e1d1347389f2ab93d60773d4d   6902644   \n4  8842281e1d1347389f2ab93d60773d4d   9844623   \n\n                          review_id  is_read  rating review_text_incomplete  \\\n0  6b4db26aafeaf0da77c7de6214331e1e    False       0                          \n1  99b27059f711c37de8f90ee8e4dc0d1b    False       0                          \n2  cb944d94854df5afd22210bb0aa0c903    False       0                          \n3  2711bac2a8cc600dae1590a6ca0edb34    False       0                          \n4  b72979076d1cded25dded922195e5b1c    False       0                          \n\n                       date_added                    date_updated read_at  \\\n0  Mon Aug 21 12:11:00 -0700 2017  Mon Aug 21 12:11:00 -0700 2017           \n1  Fri Feb 24 08:59:44 -0800 2017  Fri Feb 24 08:59:44 -0800 2017           \n2  Wed May 20 21:28:56 -0700 2015  Wed May 20 21:28:57 -0700 2015           \n3  Sun Jun 01 17:25:23 -0700 2014  Sun Jun 01 17:25:23 -0700 2014           \n4  Sun Sep 02 08:45:08 -0700 2012  Sun Sep 02 08:45:08 -0700 2012           \n\n  started_at  \n0             \n1             \n2             \n3             \n4             ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>book_id</th>\n      <th>review_id</th>\n      <th>is_read</th>\n      <th>rating</th>\n      <th>review_text_incomplete</th>\n      <th>date_added</th>\n      <th>date_updated</th>\n      <th>read_at</th>\n      <th>started_at</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8842281e1d1347389f2ab93d60773d4d</td>\n      <td>836610</td>\n      <td>6b4db26aafeaf0da77c7de6214331e1e</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td>Mon Aug 21 12:11:00 -0700 2017</td>\n      <td>Mon Aug 21 12:11:00 -0700 2017</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8842281e1d1347389f2ab93d60773d4d</td>\n      <td>7648967</td>\n      <td>99b27059f711c37de8f90ee8e4dc0d1b</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td>Fri Feb 24 08:59:44 -0800 2017</td>\n      <td>Fri Feb 24 08:59:44 -0800 2017</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8842281e1d1347389f2ab93d60773d4d</td>\n      <td>15704307</td>\n      <td>cb944d94854df5afd22210bb0aa0c903</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td>Wed May 20 21:28:56 -0700 2015</td>\n      <td>Wed May 20 21:28:57 -0700 2015</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8842281e1d1347389f2ab93d60773d4d</td>\n      <td>6902644</td>\n      <td>2711bac2a8cc600dae1590a6ca0edb34</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td>Sun Jun 01 17:25:23 -0700 2014</td>\n      <td>Sun Jun 01 17:25:23 -0700 2014</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8842281e1d1347389f2ab93d60773d4d</td>\n      <td>9844623</td>\n      <td>b72979076d1cded25dded922195e5b1c</td>\n      <td>False</td>\n      <td>0</td>\n      <td></td>\n      <td>Sun Sep 02 08:45:08 -0700 2012</td>\n      <td>Sun Sep 02 08:45:08 -0700 2012</td>\n      <td></td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goodreads_reviews_comics_graphic.json.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:01, 84043.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 100000 rows.\n"
     ]
    },
    {
     "data": {
      "text/plain": "                            user_id   book_id  \\\n0  dc3763cdb9b2cae805882878eebb6a32  18471619   \n1  bafc2d50014200cda7cb2b6acd60cd73   6315584   \n2  bafc2d50014200cda7cb2b6acd60cd73  29847729   \n3  bafc2d50014200cda7cb2b6acd60cd73  18454118   \n4  bafc2d50014200cda7cb2b6acd60cd73   2239435   \n\n                          review_id  rating  \\\n0  66b2ba840f9bd36d6d27f46136fe4772       3   \n1  72f1229aba5a88f9e72f0dcdc007dd22       4   \n2  a75309355f8662caaa5e2c92ab693d3f       4   \n3  c3cc5a3e1d6b6c9cf1c044f306c8e752       5   \n4  cc444be37ab0a42bfb4dd818cb5edd10       4   \n\n                                         review_text  \\\n0  Sherlock Holmes and the Vampires of London \\n ...   \n1  I've never really liked Spider-Man. I am, howe...   \n2  A very quick introduction, this is coming out ...   \n3  I've been waiting so long for this. I first st...   \n4  The only thing more entertaining than this boo...   \n\n                       date_added                    date_updated  \\\n0  Thu Dec 05 10:44:25 -0800 2013  Thu Dec 05 10:45:15 -0800 2013   \n1  Wed Aug 10 06:06:48 -0700 2016  Fri Aug 12 08:49:54 -0700 2016   \n2  Thu Apr 21 07:44:00 -0700 2016  Thu Apr 21 07:59:28 -0700 2016   \n3  Mon Mar 03 17:45:56 -0800 2014  Mon Mar 03 17:54:11 -0800 2014   \n4  Wed Apr 03 12:37:48 -0700 2013  Wed Apr 03 13:03:36 -0700 2013   \n\n                          read_at                      started_at  n_votes  \\\n0  Tue Nov 05 00:00:00 -0800 2013                                        0   \n1  Fri Aug 12 08:49:54 -0700 2016  Wed Aug 10 00:00:00 -0700 2016        0   \n2  Thu Apr 21 07:59:28 -0700 2016  Thu Apr 21 00:00:00 -0700 2016        0   \n3  Sat Mar 01 00:00:00 -0800 2014  Sat Mar 01 00:00:00 -0800 2014        1   \n4  Wed Apr 03 13:03:36 -0700 2013                                        0   \n\n   n_comments  \n0           0  \n1           0  \n2           0  \n3           0  \n4           0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>book_id</th>\n      <th>review_id</th>\n      <th>rating</th>\n      <th>review_text</th>\n      <th>date_added</th>\n      <th>date_updated</th>\n      <th>read_at</th>\n      <th>started_at</th>\n      <th>n_votes</th>\n      <th>n_comments</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dc3763cdb9b2cae805882878eebb6a32</td>\n      <td>18471619</td>\n      <td>66b2ba840f9bd36d6d27f46136fe4772</td>\n      <td>3</td>\n      <td>Sherlock Holmes and the Vampires of London \\n ...</td>\n      <td>Thu Dec 05 10:44:25 -0800 2013</td>\n      <td>Thu Dec 05 10:45:15 -0800 2013</td>\n      <td>Tue Nov 05 00:00:00 -0800 2013</td>\n      <td></td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bafc2d50014200cda7cb2b6acd60cd73</td>\n      <td>6315584</td>\n      <td>72f1229aba5a88f9e72f0dcdc007dd22</td>\n      <td>4</td>\n      <td>I've never really liked Spider-Man. I am, howe...</td>\n      <td>Wed Aug 10 06:06:48 -0700 2016</td>\n      <td>Fri Aug 12 08:49:54 -0700 2016</td>\n      <td>Fri Aug 12 08:49:54 -0700 2016</td>\n      <td>Wed Aug 10 00:00:00 -0700 2016</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bafc2d50014200cda7cb2b6acd60cd73</td>\n      <td>29847729</td>\n      <td>a75309355f8662caaa5e2c92ab693d3f</td>\n      <td>4</td>\n      <td>A very quick introduction, this is coming out ...</td>\n      <td>Thu Apr 21 07:44:00 -0700 2016</td>\n      <td>Thu Apr 21 07:59:28 -0700 2016</td>\n      <td>Thu Apr 21 07:59:28 -0700 2016</td>\n      <td>Thu Apr 21 00:00:00 -0700 2016</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>bafc2d50014200cda7cb2b6acd60cd73</td>\n      <td>18454118</td>\n      <td>c3cc5a3e1d6b6c9cf1c044f306c8e752</td>\n      <td>5</td>\n      <td>I've been waiting so long for this. I first st...</td>\n      <td>Mon Mar 03 17:45:56 -0800 2014</td>\n      <td>Mon Mar 03 17:54:11 -0800 2014</td>\n      <td>Sat Mar 01 00:00:00 -0800 2014</td>\n      <td>Sat Mar 01 00:00:00 -0800 2014</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bafc2d50014200cda7cb2b6acd60cd73</td>\n      <td>2239435</td>\n      <td>cc444be37ab0a42bfb4dd818cb5edd10</td>\n      <td>4</td>\n      <td>The only thing more entertaining than this boo...</td>\n      <td>Wed Apr 03 12:37:48 -0700 2013</td>\n      <td>Wed Apr 03 13:03:36 -0700 2013</td>\n      <td>Wed Apr 03 13:03:36 -0700 2013</td>\n      <td></td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = \"data/\"\n",
    "books = \"goodreads_books_comics_graphic.json.gz\"\n",
    "interactions = \"goodreads_interactions_comics_graphic.json.gz\"\n",
    "reviews = \"goodreads_reviews_comics_graphic.json.gz\"\n",
    "datasets = {books: None, interactions: None, reviews: None}\n",
    "\n",
    "n = 100000\n",
    "datafile = reviews\n",
    "k = 10\n",
    "epochs = 10\n",
    "\n",
    "for filename in datasets.keys():\n",
    "    print(filename)\n",
    "    datasets[filename] = parse_json(data_path + filename, n)\n",
    "    display(datasets[filename].head(5))\n",
    "\n",
    "books_df = datasets[books][[\"book_id\", \"title\"]].copy()\n",
    "interactions_df = datasets[datafile][[\"user_id\", \"book_id\", \"rating\", \"date_updated\"]].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "format_str = \"%a %b %d %H:%M:%S %z %Y\"\n",
    "interactions_df[\"date_updated\"] = pd.to_datetime(interactions_df[\"date_updated\"], format=format_str)\n",
    "\n",
    "books_df[\"book_id\"] = books_df[\"book_id\"].astype(\"int64\")\n",
    "interactions_df[\"book_id\"] = interactions_df[\"book_id\"].astype(\"int64\")\n",
    "\n",
    "interactions_df = interactions_df.sort_values(by=[\"user_id\", \"date_updated\"], ascending=[True, True])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:00<00:00, 1109874.36it/s]\n",
      "100%|██████████| 89411/89411 [00:00<00:00, 1067636.46it/s]\n",
      "100%|██████████| 100000/100000 [00:00<00:00, 978391.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "    book_id                                              title  book_id_int\n0  25742454                              The Switchblade Mamma            0\n1  30128855                                            Cruelle            1\n2  13571772  Captain America: Winter Soldier (The Ultimate ...            2\n3  35452242  Bounty Hunter 4/3: My Life in Combat from Mari...            3\n4    707611                          Superman Archives, Vol. 2            4\n5   2250580                            A.I. Revolution, Vol. 1            5\n6  27036536                              War Stories, Volume 3            6\n7  27036537                                 Crossed, Volume 15            7\n8  27036538  Crossed + One Hundred, Volume 2 (Crossed +100 #2)            8\n9  27036539                              War Stories, Volume 4            9",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>book_id</th>\n      <th>title</th>\n      <th>book_id_int</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>25742454</td>\n      <td>The Switchblade Mamma</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>30128855</td>\n      <td>Cruelle</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13571772</td>\n      <td>Captain America: Winter Soldier (The Ultimate ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35452242</td>\n      <td>Bounty Hunter 4/3: My Life in Combat from Mari...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>707611</td>\n      <td>Superman Archives, Vol. 2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2250580</td>\n      <td>A.I. Revolution, Vol. 1</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>27036536</td>\n      <td>War Stories, Volume 3</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>27036537</td>\n      <td>Crossed, Volume 15</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>27036538</td>\n      <td>Crossed + One Hundred, Volume 2 (Crossed +100 #2)</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>27036539</td>\n      <td>War Stories, Volume 4</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                user_id   book_id  rating  \\\n54004  000192962b87d560f00b06fdcbd71681  30025791       5   \n60060  0019be35f5c9e0ea5cb8263aba085de4    533016       5   \n50111  001eb567b3331c3ef3291a801d31be4a     30515       5   \n15201  0021e047a599f9827d75628db22097b6  11020991       3   \n32571  00254cd48d3d8a99ca9f0ed44fa69d5f     29800       4   \n32570  00254cd48d3d8a99ca9f0ed44fa69d5f     29801       4   \n75011  002a023d3de233b4bd3ec4fc3e9c581a    916755       4   \n75025  002a023d3de233b4bd3ec4fc3e9c581a  12550154       4   \n75021  002a023d3de233b4bd3ec4fc3e9c581a   8044557       3   \n75024  002a023d3de233b4bd3ec4fc3e9c581a  10974311       0   \n\n                    date_updated  user_id_int  book_id_int  \n54004  2017-01-28 09:56:08-08:00            0        38788  \n60060  2014-01-23 20:17:21-08:00            1        52841  \n50111  2016-06-28 01:30:08-07:00            2        31925  \n15201  2014-03-04 08:08:19-08:00            3        24192  \n32571  2013-04-01 16:54:17-07:00            4        76189  \n32570  2013-04-01 16:55:34-07:00            4        76190  \n75011  2016-04-01 00:17:23-07:00            5        18645  \n75025  2016-04-01 00:44:45-07:00            5        19450  \n75021  2016-04-01 00:58:56-07:00            5          945  \n75024  2016-04-01 01:01:29-07:00            5        85254  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>book_id</th>\n      <th>rating</th>\n      <th>date_updated</th>\n      <th>user_id_int</th>\n      <th>book_id_int</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>54004</th>\n      <td>000192962b87d560f00b06fdcbd71681</td>\n      <td>30025791</td>\n      <td>5</td>\n      <td>2017-01-28 09:56:08-08:00</td>\n      <td>0</td>\n      <td>38788</td>\n    </tr>\n    <tr>\n      <th>60060</th>\n      <td>0019be35f5c9e0ea5cb8263aba085de4</td>\n      <td>533016</td>\n      <td>5</td>\n      <td>2014-01-23 20:17:21-08:00</td>\n      <td>1</td>\n      <td>52841</td>\n    </tr>\n    <tr>\n      <th>50111</th>\n      <td>001eb567b3331c3ef3291a801d31be4a</td>\n      <td>30515</td>\n      <td>5</td>\n      <td>2016-06-28 01:30:08-07:00</td>\n      <td>2</td>\n      <td>31925</td>\n    </tr>\n    <tr>\n      <th>15201</th>\n      <td>0021e047a599f9827d75628db22097b6</td>\n      <td>11020991</td>\n      <td>3</td>\n      <td>2014-03-04 08:08:19-08:00</td>\n      <td>3</td>\n      <td>24192</td>\n    </tr>\n    <tr>\n      <th>32571</th>\n      <td>00254cd48d3d8a99ca9f0ed44fa69d5f</td>\n      <td>29800</td>\n      <td>4</td>\n      <td>2013-04-01 16:54:17-07:00</td>\n      <td>4</td>\n      <td>76189</td>\n    </tr>\n    <tr>\n      <th>32570</th>\n      <td>00254cd48d3d8a99ca9f0ed44fa69d5f</td>\n      <td>29801</td>\n      <td>4</td>\n      <td>2013-04-01 16:55:34-07:00</td>\n      <td>4</td>\n      <td>76190</td>\n    </tr>\n    <tr>\n      <th>75011</th>\n      <td>002a023d3de233b4bd3ec4fc3e9c581a</td>\n      <td>916755</td>\n      <td>4</td>\n      <td>2016-04-01 00:17:23-07:00</td>\n      <td>5</td>\n      <td>18645</td>\n    </tr>\n    <tr>\n      <th>75025</th>\n      <td>002a023d3de233b4bd3ec4fc3e9c581a</td>\n      <td>12550154</td>\n      <td>4</td>\n      <td>2016-04-01 00:44:45-07:00</td>\n      <td>5</td>\n      <td>19450</td>\n    </tr>\n    <tr>\n      <th>75021</th>\n      <td>002a023d3de233b4bd3ec4fc3e9c581a</td>\n      <td>8044557</td>\n      <td>3</td>\n      <td>2016-04-01 00:58:56-07:00</td>\n      <td>5</td>\n      <td>945</td>\n    </tr>\n    <tr>\n      <th>75024</th>\n      <td>002a023d3de233b4bd3ec4fc3e9c581a</td>\n      <td>10974311</td>\n      <td>0</td>\n      <td>2016-04-01 01:01:29-07:00</td>\n      <td>5</td>\n      <td>85254</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def apply_consecutive_mapping(dataframe: pd.DataFrame, column: str, new_column: str, *additional: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Generates a consecutive ID column for the values of an existing column. Also adds this column to additional data\n",
    "    frames with the exact same mapping of old ID to new (consecutive) ID.\n",
    "    \"\"\"\n",
    "    ids = {}\n",
    "\n",
    "    def map_to_consecutive_ids(uuid: Union[int, np.int64]) -> int:\n",
    "        \"\"\"\n",
    "        To be used with `pd.Dataframe.apply()` or `pd.Dataframe.progress_apply()`; returns a unique ID per distinct value.\n",
    "        (Using the function attribute `map_to_consecutive_ids.ids` to avoid namespace pollution.\n",
    "        \"\"\"\n",
    "        if uuid not in ids:\n",
    "            ids[uuid] = len(ids)\n",
    "        return ids[uuid]\n",
    "\n",
    "    dataframe[new_column] = dataframe[column].progress_apply(map_to_consecutive_ids)\n",
    "    for frame in additional:\n",
    "        frame[new_column] = frame[column].progress_apply(lambda old_id: ids.get(old_id, -1))\n",
    "\n",
    "\n",
    "apply_consecutive_mapping(interactions_df, \"user_id\", \"user_id_int\")\n",
    "apply_consecutive_mapping(books_df, \"book_id\", \"book_id_int\", interactions_df)\n",
    "\n",
    "display(books_df.head(10))\n",
    "display(interactions_df.head(10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing\n",
    "\n",
    "We apply the following preprocessing steps:\n",
    "\n",
    "- Reconsumption item removal, although there aren't many (or even none at all) of these in the dataset.\n",
    "\n",
    "- Infrequent item removal; we remove any items that have less than a certain number (5) of interactions/ratings.\n",
    "\n",
    "- Infrequent user removal; we remove users with less that the same certain number (5) of interactions/ratings."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "       user_id  item_id                   datetime  rating\n54004        0    38788  2017-01-28 09:56:08-08:00       5\n60060        1    52841  2014-01-23 20:17:21-08:00       5\n50111        2    31925  2016-06-28 01:30:08-07:00       5\n15201        3    24192  2014-03-04 08:08:19-08:00       3\n32571        4    76189  2013-04-01 16:54:17-07:00       4\n32570        4    76190  2013-04-01 16:55:34-07:00       4\n75011        5    18645  2016-04-01 00:17:23-07:00       4\n75025        5    19450  2016-04-01 00:44:45-07:00       4\n75021        5      945  2016-04-01 00:58:56-07:00       3\n75024        5    85254  2016-04-01 01:01:29-07:00       0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>datetime</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>54004</th>\n      <td>0</td>\n      <td>38788</td>\n      <td>2017-01-28 09:56:08-08:00</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>60060</th>\n      <td>1</td>\n      <td>52841</td>\n      <td>2014-01-23 20:17:21-08:00</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>50111</th>\n      <td>2</td>\n      <td>31925</td>\n      <td>2016-06-28 01:30:08-07:00</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>15201</th>\n      <td>3</td>\n      <td>24192</td>\n      <td>2014-03-04 08:08:19-08:00</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>32571</th>\n      <td>4</td>\n      <td>76189</td>\n      <td>2013-04-01 16:54:17-07:00</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>32570</th>\n      <td>4</td>\n      <td>76190</td>\n      <td>2013-04-01 16:55:34-07:00</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>75011</th>\n      <td>5</td>\n      <td>18645</td>\n      <td>2016-04-01 00:17:23-07:00</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>75025</th>\n      <td>5</td>\n      <td>19450</td>\n      <td>2016-04-01 00:44:45-07:00</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>75021</th>\n      <td>5</td>\n      <td>945</td>\n      <td>2016-04-01 00:58:56-07:00</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>75024</th>\n      <td>5</td>\n      <td>85254</td>\n      <td>2016-04-01 01:01:29-07:00</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 9016\n",
      "Number of unique items: 35714\n",
      "100000 initial rows\n",
      "100000 rows after removing reconsumption items\n",
      "46657 rows after removing infrequent items and users\n",
      "Number of unique users: 2657\n",
      "Number of unique items: 3682\n"
     ]
    },
    {
     "data": {
      "text/plain": "    user_id  item_id                   datetime  rating\n8         5      945  2016-04-01 00:58:56-07:00       3\n9         5    85254  2016-04-01 01:01:29-07:00       0\n10        5    63080  2016-04-01 01:02:25-07:00       3\n13        5    44739  2016-04-01 01:14:37-07:00       4\n15        5    36018  2016-04-21 00:32:09-07:00       4\n17        5    17524  2016-04-21 18:43:32-07:00       3\n18        5     2749  2016-08-11 09:20:40-07:00       3\n21        5    31777  2016-08-11 09:35:30-07:00       5\n24        5      973  2016-09-30 21:08:43-07:00       3\n25        5    54896  2016-09-30 21:08:44-07:00       4",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>datetime</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8</th>\n      <td>5</td>\n      <td>945</td>\n      <td>2016-04-01 00:58:56-07:00</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>5</td>\n      <td>85254</td>\n      <td>2016-04-01 01:01:29-07:00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>5</td>\n      <td>63080</td>\n      <td>2016-04-01 01:02:25-07:00</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>5</td>\n      <td>44739</td>\n      <td>2016-04-01 01:14:37-07:00</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>5</td>\n      <td>36018</td>\n      <td>2016-04-21 00:32:09-07:00</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>5</td>\n      <td>17524</td>\n      <td>2016-04-21 18:43:32-07:00</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>5</td>\n      <td>2749</td>\n      <td>2016-08-11 09:20:40-07:00</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>5</td>\n      <td>31777</td>\n      <td>2016-08-11 09:35:30-07:00</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>5</td>\n      <td>973</td>\n      <td>2016-09-30 21:08:43-07:00</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>5</td>\n      <td>54896</td>\n      <td>2016-09-30 21:08:44-07:00</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess(df: pd.DataFrame, min_support: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Removes reconsumption items, items that have less than `min_support` interactions, and users that have less than\n",
    "    `min_support` interactions. In some cases, removing an infrequent item may turn a frequent user into an infrequent\n",
    "    one, and vice versa. In these cases, we don't remove the now infrequent user/item, we only consider the original\n",
    "    frequency. As such, the preprocessed dataset may contain some users and items that don't reach the minimum support\n",
    "    limit.\n",
    "    \"\"\"\n",
    "    print(df.shape[0], \"initial rows\")\n",
    "    # Drop reconsumption items\n",
    "    df = df.drop_duplicates(subset=[\"user_id\", \"item_id\"])\n",
    "    print(df.shape[0], \"rows after removing reconsumption items\")\n",
    "    # Compute user and item counts\n",
    "    g1 = df.groupby(\"item_id\", as_index=False)[\"user_id\"].size()\n",
    "    g1 = g1.rename({\"size\": \"users_per_item\"}, axis=\"columns\")\n",
    "    g2 = df.groupby(\"user_id\", as_index=False)[\"item_id\"].size()\n",
    "    g2 = g2.rename({\"size\": \"items_per_user\"}, axis=\"columns\")\n",
    "    df = pd.merge(df, g1, how=\"left\", on=[\"item_id\"])\n",
    "    df = pd.merge(df, g2, how=\"left\", on=[\"user_id\"])\n",
    "    # Drop items and users with less than `min_support` interactions\n",
    "    df = df[(df[\"users_per_item\"] >= min_support) & (df[\"items_per_user\"] >= min_support)]\n",
    "    print(df.shape[0], \"rows after removing infrequent items and users\")\n",
    "    df.drop(columns=[\"users_per_item\", \"items_per_user\"], inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "processed_df = interactions_df[[\"user_id_int\", \"book_id_int\", \"date_updated\", \"rating\"]].copy()\n",
    "processed_df = processed_df.rename(\n",
    "    columns={\"user_id_int\": \"user_id\", \"book_id_int\": \"item_id\", \"date_updated\": \"datetime\"})\n",
    "display(processed_df.head(10))\n",
    "print(f\"Number of unique users:\", processed_df[\"user_id\"].nunique())\n",
    "print(f\"Number of unique items:\", processed_df[\"item_id\"].nunique())\n",
    "processed_df = preprocess(processed_df)\n",
    "print(f\"Number of unique users:\", processed_df[\"user_id\"].nunique())\n",
    "print(f\"Number of unique items:\", processed_df[\"item_id\"].nunique())\n",
    "display(processed_df.head(10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def split(items: list[int], percentage_train: float) -> pd.Series:\n",
    "    nr_train_items = int(len(items) * percentage_train)\n",
    "    return pd.Series((items[: nr_train_items], items[nr_train_items:]))\n",
    "\n",
    "\n",
    "sessions_df = processed_df.groupby(by=\"user_id\", as_index=False)[[\"item_id\", \"datetime\", \"rating\"]].agg(list)\n",
    "display(sessions_df.head(5))\n",
    "\n",
    "percentage_train = 0.8\n",
    "sessions_df[[\"item_id_history\", \"item_id_future\"]] = sessions_df[\"item_id\"].progress_apply(split,\n",
    "                                                                                           args=(percentage_train,))\n",
    "sessions_df[[\"rating_history\", \"rating_future\"]] = sessions_df[\"rating\"].progress_apply(split, args=(percentage_train,))\n",
    "display(sessions_df.head(5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id                                            item_id  \\\n0        5  [945, 85254, 63080, 44739, 36018, 17524, 2749,...   \n1        6   [58655, 21663, 84762, 5703, 47916, 70258, 43524]   \n2       10  [44739, 49712, 34074, 64190, 10700, 71828, 430...   \n3       13  [10740, 73775, 46111, 72982, 88824, 42840, 827...   \n4       15          [87706, 3861, 53792, 30798, 40410, 67727]   \n\n                                            datetime  \\\n0  [2016-04-01 00:58:56-07:00, 2016-04-01 01:01:2...   \n1  [2017-05-24 14:07:48-07:00, 2017-07-10 10:55:2...   \n2  [2014-06-04 11:35:45-07:00, 2014-11-11 20:50:2...   \n3  [2008-04-21 10:17:04-07:00, 2009-08-16 20:40:0...   \n4  [2014-10-17 16:50:25-07:00, 2015-04-18 15:30:2...   \n\n                                              rating  \n0  [3, 0, 3, 4, 4, 3, 3, 5, 3, 4, 4, 4, 4, 3, 4, ...  \n1                              [1, 3, 1, 3, 3, 4, 3]  \n2  [1, 3, 4, 1, 3, 3, 4, 5, 3, 4, 4, 4, 5, 2, 5, ...  \n3      [4, 3, 5, 3, 4, 3, 4, 4, 3, 4, 4, 5, 5, 4, 5]  \n4                                 [5, 4, 5, 5, 4, 3]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>datetime</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>[945, 85254, 63080, 44739, 36018, 17524, 2749,...</td>\n      <td>[2016-04-01 00:58:56-07:00, 2016-04-01 01:01:2...</td>\n      <td>[3, 0, 3, 4, 4, 3, 3, 5, 3, 4, 4, 4, 4, 3, 4, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6</td>\n      <td>[58655, 21663, 84762, 5703, 47916, 70258, 43524]</td>\n      <td>[2017-05-24 14:07:48-07:00, 2017-07-10 10:55:2...</td>\n      <td>[1, 3, 1, 3, 3, 4, 3]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10</td>\n      <td>[44739, 49712, 34074, 64190, 10700, 71828, 430...</td>\n      <td>[2014-06-04 11:35:45-07:00, 2014-11-11 20:50:2...</td>\n      <td>[1, 3, 4, 1, 3, 3, 4, 5, 3, 4, 4, 4, 5, 2, 5, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13</td>\n      <td>[10740, 73775, 46111, 72982, 88824, 42840, 827...</td>\n      <td>[2008-04-21 10:17:04-07:00, 2009-08-16 20:40:0...</td>\n      <td>[4, 3, 5, 3, 4, 3, 4, 4, 3, 4, 4, 5, 5, 4, 5]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>15</td>\n      <td>[87706, 3861, 53792, 30798, 40410, 67727]</td>\n      <td>[2014-10-17 16:50:25-07:00, 2015-04-18 15:30:2...</td>\n      <td>[5, 4, 5, 5, 4, 3]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2657/2657 [00:00<00:00, 8576.89it/s] \n",
      "100%|██████████| 2657/2657 [00:00<00:00, 8363.13it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": "   user_id                                            item_id  \\\n0        5  [945, 85254, 63080, 44739, 36018, 17524, 2749,...   \n1        6   [58655, 21663, 84762, 5703, 47916, 70258, 43524]   \n2       10  [44739, 49712, 34074, 64190, 10700, 71828, 430...   \n3       13  [10740, 73775, 46111, 72982, 88824, 42840, 827...   \n4       15          [87706, 3861, 53792, 30798, 40410, 67727]   \n\n                                            datetime  \\\n0  [2016-04-01 00:58:56-07:00, 2016-04-01 01:01:2...   \n1  [2017-05-24 14:07:48-07:00, 2017-07-10 10:55:2...   \n2  [2014-06-04 11:35:45-07:00, 2014-11-11 20:50:2...   \n3  [2008-04-21 10:17:04-07:00, 2009-08-16 20:40:0...   \n4  [2014-10-17 16:50:25-07:00, 2015-04-18 15:30:2...   \n\n                                              rating  \\\n0  [3, 0, 3, 4, 4, 3, 3, 5, 3, 4, 4, 4, 4, 3, 4, ...   \n1                              [1, 3, 1, 3, 3, 4, 3]   \n2  [1, 3, 4, 1, 3, 3, 4, 5, 3, 4, 4, 4, 5, 2, 5, ...   \n3      [4, 3, 5, 3, 4, 3, 4, 4, 3, 4, 4, 5, 5, 4, 5]   \n4                                 [5, 4, 5, 5, 4, 3]   \n\n                                     item_id_history  \\\n0  [945, 85254, 63080, 44739, 36018, 17524, 2749,...   \n1                 [58655, 21663, 84762, 5703, 47916]   \n2  [44739, 49712, 34074, 64190, 10700, 71828, 430...   \n3  [10740, 73775, 46111, 72982, 88824, 42840, 827...   \n4                        [87706, 3861, 53792, 30798]   \n\n                                     item_id_future  \\\n0                      [27227, 71060, 22211, 62482]   \n1                                    [70258, 43524]   \n2  [48597, 29015, 19669, 2624, 84659, 12857, 48767]   \n3                             [16907, 84322, 81142]   \n4                                    [40410, 67727]   \n\n                                      rating_history          rating_future  \n0            [3, 0, 3, 4, 4, 3, 3, 5, 3, 4, 4, 4, 4]           [3, 4, 3, 5]  \n1                                    [1, 3, 1, 3, 3]                 [4, 3]  \n2  [1, 3, 4, 1, 3, 3, 4, 5, 3, 4, 4, 4, 5, 2, 5, ...  [3, 5, 5, 5, 2, 4, 5]  \n3               [4, 3, 5, 3, 4, 3, 4, 4, 3, 4, 4, 5]              [5, 4, 5]  \n4                                       [5, 4, 5, 5]                 [4, 3]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>datetime</th>\n      <th>rating</th>\n      <th>item_id_history</th>\n      <th>item_id_future</th>\n      <th>rating_history</th>\n      <th>rating_future</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>[945, 85254, 63080, 44739, 36018, 17524, 2749,...</td>\n      <td>[2016-04-01 00:58:56-07:00, 2016-04-01 01:01:2...</td>\n      <td>[3, 0, 3, 4, 4, 3, 3, 5, 3, 4, 4, 4, 4, 3, 4, ...</td>\n      <td>[945, 85254, 63080, 44739, 36018, 17524, 2749,...</td>\n      <td>[27227, 71060, 22211, 62482]</td>\n      <td>[3, 0, 3, 4, 4, 3, 3, 5, 3, 4, 4, 4, 4]</td>\n      <td>[3, 4, 3, 5]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6</td>\n      <td>[58655, 21663, 84762, 5703, 47916, 70258, 43524]</td>\n      <td>[2017-05-24 14:07:48-07:00, 2017-07-10 10:55:2...</td>\n      <td>[1, 3, 1, 3, 3, 4, 3]</td>\n      <td>[58655, 21663, 84762, 5703, 47916]</td>\n      <td>[70258, 43524]</td>\n      <td>[1, 3, 1, 3, 3]</td>\n      <td>[4, 3]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10</td>\n      <td>[44739, 49712, 34074, 64190, 10700, 71828, 430...</td>\n      <td>[2014-06-04 11:35:45-07:00, 2014-11-11 20:50:2...</td>\n      <td>[1, 3, 4, 1, 3, 3, 4, 5, 3, 4, 4, 4, 5, 2, 5, ...</td>\n      <td>[44739, 49712, 34074, 64190, 10700, 71828, 430...</td>\n      <td>[48597, 29015, 19669, 2624, 84659, 12857, 48767]</td>\n      <td>[1, 3, 4, 1, 3, 3, 4, 5, 3, 4, 4, 4, 5, 2, 5, ...</td>\n      <td>[3, 5, 5, 5, 2, 4, 5]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13</td>\n      <td>[10740, 73775, 46111, 72982, 88824, 42840, 827...</td>\n      <td>[2008-04-21 10:17:04-07:00, 2009-08-16 20:40:0...</td>\n      <td>[4, 3, 5, 3, 4, 3, 4, 4, 3, 4, 4, 5, 5, 4, 5]</td>\n      <td>[10740, 73775, 46111, 72982, 88824, 42840, 827...</td>\n      <td>[16907, 84322, 81142]</td>\n      <td>[4, 3, 5, 3, 4, 3, 4, 4, 3, 4, 4, 5]</td>\n      <td>[5, 4, 5]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>15</td>\n      <td>[87706, 3861, 53792, 30798, 40410, 67727]</td>\n      <td>[2014-10-17 16:50:25-07:00, 2015-04-18 15:30:2...</td>\n      <td>[5, 4, 5, 5, 4, 3]</td>\n      <td>[87706, 3861, 53792, 30798]</td>\n      <td>[40410, 67727]</td>\n      <td>[5, 4, 5, 5]</td>\n      <td>[4, 3]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def create_sparse_matrix(dataframe: pd.DataFrame, item_id_column: str, value_column: str = None,\n",
    "                         shape: tuple[int, int] = None) -> sparse.csr_matrix:\n",
    "    \"\"\"\n",
    "    Creates a sparse matrix from the data in `dataframe`.\n",
    "    \"\"\"\n",
    "    # Flatten the dataframe\n",
    "    user_ids = []\n",
    "    item_ids = []\n",
    "    values = []\n",
    "    for index, row in dataframe.iterrows():\n",
    "        user_ids.extend([row[\"user_id\"]] * len(row[item_id_column]))\n",
    "        item_ids.extend(row[item_id_column])\n",
    "        if value_column is not None:\n",
    "            values.extend(row[value_column])\n",
    "    if value_column is None:\n",
    "        values = np.ones(len(user_ids))\n",
    "    # Create the CSR matrix\n",
    "    return sparse.csr_matrix((values, (user_ids, item_ids)), shape=shape, dtype=np.int32)\n",
    "\n",
    "\n",
    "shape = (processed_df[\"user_id\"].max() + 1, processed_df[\"item_id\"].max() + 1)\n",
    "# train = create_sparse_matrix(sessions_df, \"item_id_history\", \"rating_history\", shape)\n",
    "# true = create_sparse_matrix(sessions_df, \"item_id_future\", \"rating_future\", shape)\n",
    "train = create_sparse_matrix(sessions_df, \"item_id_history\", None, shape)\n",
    "true = create_sparse_matrix(sessions_df, \"item_id_future\", None, shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Popularity recommender"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class PopularityRecommender:\n",
    "    def __init__(self, k: int = 10) -> None:\n",
    "        self.k = k\n",
    "        self.scores = []\n",
    "\n",
    "    def fit(self, data: sparse.csr_matrix) -> None:\n",
    "        items = list(data.nonzero()[1])\n",
    "        scores = Counter(items).most_common(self.k)\n",
    "        self.scores = [(item, score / scores[0][1]) for item, score in scores]\n",
    "\n",
    "    def predict(self, data: sparse.csr_matrix) -> sparse.csr_matrix:\n",
    "        items, values = zip(*self.scores)\n",
    "        users = set(data.nonzero()[0])\n",
    "\n",
    "        matrix_data = ([], ([], []))\n",
    "        for user in users:\n",
    "            matrix_data[0].extend(values)\n",
    "            matrix_data[1][0].extend([user] * self.k)\n",
    "            matrix_data[1][1].extend(items)\n",
    "        return sparse.csr_matrix(matrix_data, shape=data.shape)\n",
    "\n",
    "# recommender = PopularityRecommender(k)\n",
    "# recommender.fit(train)\n",
    "# predicted = recommender.predict(train)\n",
    "# print(predicted)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation\n",
    "\n",
    "The evaluation metrics we will be using are the following:\n",
    "\n",
    "- Recall @ 10: the percentage of users where the top-10 recommendations are relevant.\n",
    "\n",
    "- NDCG @ 10: similar to recall but the sum of the hits is weighted by the place in the top 10.\n",
    "\n",
    "- Qualitative results, i.e. examples of the recommendations."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def sparse_invert_nonzero(a: sparse.csr_matrix) -> sparse.csr_matrix:\n",
    "    inverse = a.copy()\n",
    "    inverse.data = 1 / inverse.data\n",
    "    return inverse\n",
    "\n",
    "\n",
    "def sparse_divide_nonzero(a: sparse.csr_matrix, b: sparse.csr_matrix) -> sparse.csr_matrix:\n",
    "    return a.multiply(sparse_invert_nonzero(b))\n",
    "\n",
    "\n",
    "def compute_recall(true: sparse.csr_matrix, predicted: sparse.csr_matrix) -> float:\n",
    "    scores = sparse.lil_matrix(predicted.shape)\n",
    "    scores[predicted.multiply(true).astype(bool)] = 1\n",
    "    scores = sparse_divide_nonzero(scores.tocsr(), sparse.csr_matrix(true.sum(axis=1))).sum(axis=1)\n",
    "    return scores.mean()\n",
    "\n",
    "# recall = compute_recall(true, predicted)\n",
    "# print(f\"Recall @ {k}: {recall:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RBM-based recommender"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class RBMRecommender:\n",
    "    \"\"\"\n",
    "    A recommender system for ratings based on Restricted Boltzmann Machines (RBMs).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nr_items: int, nr_ratings: int, nr_hidden: int, learning_rate: float, k: int = 10) -> None:\n",
    "        # self.rng = np.random.default_rng()\n",
    "        # Training and evaluation parameters\n",
    "        self.nr_items = nr_items\n",
    "        self.nr_ratings = nr_ratings\n",
    "        self.nr_hidden = nr_hidden\n",
    "        self.learning_rate = learning_rate\n",
    "        self.k = k\n",
    "        # RBM weights and biases\n",
    "        self.weights = torch.randn((nr_items, nr_hidden))\n",
    "        self.bias_items = torch.randn(nr_items)\n",
    "        self.bias_features = torch.randn(nr_hidden)\n",
    "\n",
    "    def probability_hidden(self, visible: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" Computes `p(h_j = 1 | V)`. \"\"\"\n",
    "        return torch.sigmoid(self.bias_features + torch.matmul(visible, self.weights))\n",
    "\n",
    "    def probability_visible(self, hidden: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" Computes `p(v^k_i = 1 | h)`. \"\"\"\n",
    "        return torch.sigmoid(self.bias_items + torch.matmul(hidden, self.weights.transpose(0, 1)))\n",
    "\n",
    "    def sample_hidden(self, visible: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" Randomly samples from the conditional Bernoulli distribution defined by probability_hidden(). \"\"\"\n",
    "        return torch.bernoulli(self.probability_hidden(visible))\n",
    "\n",
    "    def sample_visible(self, hidden: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" Randomly samples from the conditional Bernoulli distribution defined by probability_visible(). \"\"\"\n",
    "        return torch.bernoulli(self.probability_visible(hidden))\n",
    "\n",
    "    def fit(self, data: sparse.csr_matrix, batch_size: int = 10, sampling_iterations: int = 1) -> None:\n",
    "        \"\"\"\n",
    "        Trains the underlying RBM with the given input data. For now, we will ignore the value of the ratings, and\n",
    "        instead look at the data as a binary interaction matrix (i.e. a value => 1, no value => 0).\n",
    "\n",
    "        :param data: A |users|x|items| sparse matrix, where each entry is the rating given by that user to that item.\n",
    "        :param batch_size: The number of users to use per mini-batch.\n",
    "        :param sampling_iterations: The number of iterations of alternating Gibbs sampling per iteration of CD.\n",
    "        \"\"\"\n",
    "        for batch_start in tqdm(range(0, data.shape[0], batch_size)):\n",
    "            batch = torch.Tensor(data[batch_start : batch_start + batch_size, :].toarray())\n",
    "            batch_t = batch.transpose(0, 1)\n",
    "\n",
    "            visible = batch\n",
    "            for _ in range(sampling_iterations):\n",
    "                hidden = self.sample_hidden(visible)\n",
    "                visible = self.sample_visible(hidden)\n",
    "                # We don't want to update any missing values, i.e. values that are 0\n",
    "                visible[batch == 0] = 0\n",
    "\n",
    "            data_sample = torch.matmul(batch_t, self.probability_hidden(batch))\n",
    "            reconstruction_sample = torch.matmul(visible.transpose(0, 1), self.probability_hidden(visible))\n",
    "\n",
    "            self.weights += self.learning_rate * (data_sample - reconstruction_sample)\n",
    "\n",
    "    def predict(self, data: sparse.csr_matrix) -> sparse.csr_matrix:\n",
    "        \"\"\" Returns predictions for each user in the data matrix. \"\"\"\n",
    "        matrix_data = ([], ([], []))  # (scores, (user IDs, item IDs))\n",
    "\n",
    "        for user_id, history in enumerate(data.iterrow()):\n",
    "            hidden = self.sample_hidden(torch.Tensor(history.toarray()))\n",
    "            visible = self.probability_visible(hidden)\n",
    "            item_ids = np.argpartition(visible, self.k)[: self.k]\n",
    "            scores = [visible[item_id] for item_id in item_ids]\n",
    "\n",
    "            matrix_data[0].extend(scores)\n",
    "            matrix_data[1][0].extend([user_id] * self.k)\n",
    "            matrix_data[1][1].extend(item_ids)\n",
    "        return sparse.csr_matrix(matrix_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 902/902 [00:33<00:00, 26.65it/s]\n",
      "100%|██████████| 902/902 [00:34<00:00, 26.49it/s]\n",
      "100%|██████████| 902/902 [00:33<00:00, 27.28it/s]\n",
      "100%|██████████| 902/902 [00:32<00:00, 27.48it/s]\n",
      "100%|██████████| 902/902 [00:34<00:00, 26.02it/s]\n",
      "100%|██████████| 902/902 [00:34<00:00, 26.28it/s]\n",
      "100%|██████████| 902/902 [00:32<00:00, 28.12it/s]\n",
      "100%|██████████| 902/902 [00:33<00:00, 27.31it/s]\n",
      "100%|██████████| 902/902 [00:32<00:00, 27.59it/s]\n",
      "100%|██████████| 902/902 [00:32<00:00, 27.37it/s]\n"
     ]
    }
   ],
   "source": [
    "recommender = RBMRecommender(train.shape[1], 0, 100, 0.01)\n",
    "for _ in range(epochs):\n",
    "    recommender.fit(train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  22211 0.001902350108139217\n",
      "  27227 0.5362015962600708\n",
      "  62482 0.0015613083960488439\n",
      "  71060 0.9978786706924438\n",
      "  43524 0.9998751878738403\n",
      "  70258 0.9669559597969055\n"
     ]
    }
   ],
   "source": [
    "for user_id in range(train.shape[0]):\n",
    "    if user_id == 10:\n",
    "        break\n",
    "    elif train.getrow(user_id).getnnz() == 0:\n",
    "        continue\n",
    "\n",
    "    prediction = recommender.predict(torch.Tensor(train.getrow(user_id).toarray()))\n",
    "    top_items = np.argpartition(prediction, k)[:k]\n",
    "\n",
    "    for item_id in true.indices[true.indptr[user_id]:true.indptr[user_id + 1]]:\n",
    "        print(f\"{item_id:7} {prediction[0][item_id]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}